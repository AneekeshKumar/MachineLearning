{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":52324,"databundleVersionId":6229904,"sourceType":"competition"},{"sourceId":3886074,"sourceType":"datasetVersion","datasetId":2308987},{"sourceId":3889637,"sourceType":"datasetVersion","datasetId":2311133},{"sourceId":4142276,"sourceType":"datasetVersion","datasetId":2446557},{"sourceId":4143520,"sourceType":"datasetVersion","datasetId":2447262}],"dockerImageVersionId":30528,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Description of the Project\n**This Project main purpose is recognising Bengali Speech/Audio and giving back Transcripts/Text. I have worked on it during a Kaggle ML Competition.**\n\n**We performs automatic speech recognition (ASR) using a pre-trained language model (LM), and returns the predicted text from the speech.**\n\n**Data :** It is clean, labelled dataset, publicly available dataset for a Kaggle Competition. \n\n**Model Used :** *Wav2Vec2ProcessorWithLM* - an implementation by HuggingFace\n","metadata":{}},{"cell_type":"code","source":"!cp -r ../input/python-packages2 ./","metadata":{"papermill":{"duration":1.21997,"end_time":"2023-07-26T05:35:04.268228","exception":false,"start_time":"2023-07-26T05:35:03.048258","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:22:10.97843Z","iopub.execute_input":"2023-08-01T02:22:10.97899Z","iopub.status.idle":"2023-08-01T02:22:12.160763Z","shell.execute_reply.started":"2023-08-01T02:22:10.978949Z","shell.execute_reply":"2023-08-01T02:22:12.159337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar xvfz ./python-packages2/jiwer.tgz\n!pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\n!tar xvfz ./python-packages2/normalizer.tgz\n!pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\n!tar xvfz ./python-packages2/pyctcdecode.tgz\n!pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n\n!tar xvfz ./python-packages2/pypikenlm.tgz\n!pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps\n!pip install pyctcdecode\n","metadata":{"papermill":{"duration":93.763363,"end_time":"2023-07-26T05:36:38.036882","exception":false,"start_time":"2023-07-26T05:35:04.273519","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:22:12.166894Z","iopub.execute_input":"2023-08-01T02:22:12.167879Z","iopub.status.idle":"2023-08-01T02:23:54.845749Z","shell.execute_reply.started":"2023-08-01T02:22:12.167813Z","shell.execute_reply":"2023-08-01T02:23:54.844601Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom glob import glob\nfrom transformers import AutoFeatureExtractor, pipeline\nimport pandas as pd\nimport librosa\nimport IPython\nfrom datasets import load_metric\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport gc\nimport wave\nfrom scipy.io import wavfile\nimport scipy.signal as sps\nimport pyctcdecode\n\ntqdm.pandas()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","metadata":{"papermill":{"duration":10.98359,"end_time":"2023-07-26T05:36:49.031675","exception":false,"start_time":"2023-07-26T05:36:38.048085","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:23:54.848273Z","iopub.execute_input":"2023-08-01T02:23:54.848673Z","iopub.status.idle":"2023-08-01T02:24:10.162979Z","shell.execute_reply.started":"2023-08-01T02:23:54.84862Z","shell.execute_reply":"2023-08-01T02:24:10.162023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CHANGE ACCORDINGLY\nBATCH_SIZE = 1\nTEST_DIRECTORY = '/kaggle/input/bengaliai-speech/test_mp3s'","metadata":{"papermill":{"duration":0.021324,"end_time":"2023-07-26T05:36:49.064238","exception":false,"start_time":"2023-07-26T05:36:49.042914","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:24:10.165695Z","iopub.execute_input":"2023-08-01T02:24:10.166519Z","iopub.status.idle":"2023-08-01T02:24:10.17374Z","shell.execute_reply.started":"2023-08-01T02:24:10.166483Z","shell.execute_reply":"2023-08-01T02:24:10.17224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass CFG:\n    my_model_name = '../input/yellowking-dlsprint-model/YellowKing_model'\n    processor_name = '../input/yellowking-dlsprint-model/YellowKing_processor'","metadata":{"papermill":{"duration":0.01868,"end_time":"2023-07-26T05:36:49.094026","exception":false,"start_time":"2023-07-26T05:36:49.075346","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:24:10.175237Z","iopub.execute_input":"2023-08-01T02:24:10.175632Z","iopub.status.idle":"2023-08-01T02:24:10.187856Z","shell.execute_reply.started":"2023-08-01T02:24:10.1756Z","shell.execute_reply":"2023-08-01T02:24:10.186901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2ProcessorWithLM\n\nprocessor = Wav2Vec2ProcessorWithLM.from_pretrained(CFG.processor_name)\n","metadata":{"papermill":{"duration":92.36403,"end_time":"2023-07-26T05:38:21.469392","exception":false,"start_time":"2023-07-26T05:36:49.105362","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:24:10.18922Z","iopub.execute_input":"2023-08-01T02:24:10.189601Z","iopub.status.idle":"2023-08-01T02:25:46.339Z","shell.execute_reply.started":"2023-08-01T02:24:10.189567Z","shell.execute_reply":"2023-08-01T02:25:46.337922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_asrLM = pipeline(\"automatic-speech-recognition\", model=CFG.my_model_name ,feature_extractor =processor.feature_extractor, tokenizer= processor.tokenizer,decoder=processor.decoder ,device=0)\n","metadata":{"papermill":{"duration":19.43293,"end_time":"2023-07-26T05:38:40.914247","exception":false,"start_time":"2023-07-26T05:38:21.481317","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:25:46.343788Z","iopub.execute_input":"2023-08-01T02:25:46.346112Z","iopub.status.idle":"2023-08-01T02:26:17.100521Z","shell.execute_reply.started":"2023-08-01T02:25:46.346074Z","shell.execute_reply":"2023-08-01T02:26:17.099519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Following Sample Submission:**","metadata":{"papermill":{"duration":0.01113,"end_time":"2023-07-26T05:38:40.93756","exception":false,"start_time":"2023-07-26T05:38:40.92643","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def infer(audio_path):\n    speech, sr = librosa.load(audio_path, sr=processor.feature_extractor.sampling_rate)\n\n    my_LM_prediction = my_asrLM(\n                speech\n            )\n\n    return my_LM_prediction['text']\n\"\"\"\nIn the provided code snippet, it appears that you are trying to implement a function named `infer` that takes an audio file path as input, performs automatic speech recognition (ASR) using a pre-trained language model (LM), and returns the predicted text from the speech. However, there are a few undefined variables and functions in the code that need clarification to understand the entire process. I'll explain the code step-by-step:\n\n1. `librosa.load(audio_path, sr=processor.feature_extractor.sampling_rate)`: This line uses the librosa library to load the audio file specified by `audio_path` and returns the audio waveform `speech` and the sample rate `sr`. The `processor.feature_extractor.sampling_rate` seems to be a variable or attribute that holds the desired sampling rate for the audio.\n\n2. `my_asrLM(speech)`: It seems like `my_asrLM` is a custom function that performs automatic speech recognition using a pre-trained language model. The input to this function is the `speech`, which is the audio waveform loaded in the previous step. This function might internally use a language model specifically trained for ASR to convert the speech into text.\n\n3. `my_LM_prediction['text']`: Assuming `my_asrLM` returns a dictionary containing various information about the ASR prediction, this line retrieves the recognized text from the ASR prediction result.\n\nBased on the provided code snippet, I can't determine the specific details of the `my_asrLM` function or the `processor.feature_extractor.sampling_rate` attribute since they are not defined in the snippet. If you can provide more context or the implementation of these functions/variables, I can help you further with the ASR inference process.\n\n\"\"\";","metadata":{"papermill":{"duration":0.021069,"end_time":"2023-07-26T05:38:40.970046","exception":false,"start_time":"2023-07-26T05:38:40.948977","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:17.101791Z","iopub.execute_input":"2023-08-01T02:26:17.106584Z","iopub.status.idle":"2023-08-01T02:26:17.117987Z","shell.execute_reply.started":"2023-08-01T02:26:17.10655Z","shell.execute_reply":"2023-08-01T02:26:17.117094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_infer(audio_paths, batch_size=BATCH_SIZE):\n    '''\n    infers on a batch of audio\n    args:\n      audio_paths  : list of path to audio files <list of string>\n    returns:\n      bangla predicted texts <list of string>\n    '''\n    results = []\n    for path in audio_paths:\n        pred = \"\"\n        try:\n            pred = infer(path)\n        except:\n            pred = \"এ\"\n        if len(pred)==0:\n            pred = \"এ\"\n        results.append(pred)\n    \n    return results\n\n\"\"\"\nThe provided code snippet defines a function named `batch_infer`, which performs inference on a batch of audio files using the `infer` function (assuming that the `infer` function is defined elsewhere in the code, and it processes a single audio file to obtain a predicted text). The function handles exceptions and returns the predicted texts for each audio file in the input list `audio_paths`.\n\nLet's break down the function step-by-step:\n\n1. `def batch_infer(audio_paths, batch_size=BATCH_SIZE):`: The function `batch_infer` takes two parameters: `audio_paths`, which is a list of file paths to audio files, and `batch_size` (defaulted to `BATCH_SIZE`, which should be defined elsewhere).\n\n2. `results = []`: Initializes an empty list named `results`, which will be used to store the predicted texts for each audio file.\n\n3. `for path in audio_paths:`: This loop iterates through each audio file path in the input list `audio_paths`.\n\n4. `pred = \"\"`: Initializes an empty string variable `pred`, which will be used to store the predicted text for the current audio file.\n\n5. `try:`: This block tries to execute the `infer` function with the current audio file path `path`.\n\n6. `pred = infer(path)`: Calls the `infer` function with the current audio file path `path` to get the predicted text for the audio file.\n\n7. `except:`: If an exception occurs during the execution of the `infer` function (e.g., an error or exception in the `infer` function), this block will be executed.\n\n8. `pred = \"এ\"`: In case of an exception, the variable `pred` is set to the Bengali character \"এ\".\n\n9. `if len(pred) == 0:`: This checks if the length of the predicted text `pred` is zero, which means no text was predicted for the audio file.\n\n10. `pred = \"এ\"`: If no text was predicted (i.e., the length is zero), the variable `pred` is set to the Bengali character \"এ\".\n\n11. `results.append(pred)`: The predicted text for the current audio file is added to the `results` list.\n\n12. `return results`: After processing all audio files in the `audio_paths` list, the function returns the `results` list, which contains the predicted texts for each audio file.\n\nIt is important to note that the `infer` function is not defined within the provided code snippet. The `infer` function is assumed to be implemented elsewhere in the code and is responsible for processing a single audio file and returning the predicted text. The `batch_infer` function, on the other hand, handles a batch of audio files by calling the `infer` function for each audio file and collecting the results in the `results` list.\n\"\"\";","metadata":{"papermill":{"duration":0.021306,"end_time":"2023-07-26T05:38:41.003302","exception":false,"start_time":"2023-07-26T05:38:40.981996","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:17.122778Z","iopub.execute_input":"2023-08-01T02:26:17.125506Z","iopub.status.idle":"2023-08-01T02:26:17.14455Z","shell.execute_reply.started":"2023-08-01T02:26:17.125473Z","shell.execute_reply":"2023-08-01T02:26:17.143714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bnunicodenormalizer import Normalizer \n\n\nbnorm = Normalizer()\ndef normalize(sen):\n    _words = [bnorm(word)['normalized']  for word in sen.split()]\n    return \" \".join([word for word in _words if word is not None])\n\ndef dari(sentence):\n    try:\n        if sentence[-1]!=\"।\":\n            sentence+=\"।\"\n    except:\n        print(sentence)\n    return sentence\n\n\"\"\"\nThe provided code snippet defines two functions, `normalize` and `dari`, that appear to be related to processing Bengali text. Let's break down each function:\n\n1. `normalize(sen)`: This function takes a Bengali sentence as input (`sen`) and returns the normalized version of the sentence. The normalization process seems to involve using the `bnunicodenormalizer` library to normalize individual words within the sentence. The function iterates through each word in the sentence, normalizes it using the `bnunicodenormalizer` library, and then joins the normalized words back into a normalized sentence. The normalized sentence will have normalized characters (e.g., combining characters) for proper rendering.\n\n   However, there's a small issue in the function. In the list comprehension used to normalize each word (`_words`), the normalization is attempted for every word, even if it contains characters that are not Bengali. The `bnunicodenormalizer` library is designed to work with Bengali text, so using it on non-Bengali characters may lead to unintended behavior or errors. If the input sentence contains non-Bengali characters, it's better to handle those cases explicitly.\n\n2. `dari(sentence)`: This function takes a Bengali sentence as input (`sentence`). It checks if the sentence ends with a Bengali full stop (U+09। - DARI). If the sentence does not end with the full stop, it appends one at the end. The purpose of this function seems to ensure that the Bengali sentence ends with the appropriate punctuation.\n\n   The function includes a `try-except` block, which is not necessary for this specific case. The code inside the `try` block simply checks the last character of the sentence. If the last character is not a full stop (DARI), it appends one. If the last character is already a full stop, no error will occur. Therefore, the `try-except` block is redundant, and the code can be simplified to just the `if` statement.\n\nIt is important to note that the code relies on an external library `bnunicodenormalizer`, which is used for Bengali Unicode normalization. Ensure that you have installed this library and imported it correctly for the code to work as intended. Additionally, the code may not handle all edge cases and may need further refinement depending on the specific use case.\n\"\"\";","metadata":{"papermill":{"duration":0.031291,"end_time":"2023-07-26T05:38:41.045913","exception":false,"start_time":"2023-07-26T05:38:41.014622","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:17.145828Z","iopub.execute_input":"2023-08-01T02:26:17.146462Z","iopub.status.idle":"2023-08-01T02:26:17.176097Z","shell.execute_reply.started":"2023-08-01T02:26:17.146386Z","shell.execute_reply":"2023-08-01T02:26:17.174932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def post_process_keys(str):\n    return str.replace(\"../input/test-wav-files-dl-sprint/test_files_wav/\",\"\").replace(\".wav\",\".mp3\")\n\n\"\"\"\nThe function `post_process_keys(str)` appears to be a post-processing function designed to modify and clean up file paths or keys (strings) related to audio files.\n\nLet's break down the function:\n\n1. `str.replace(\"../input/test-wav-files-dl-sprint/test_files_wav/\", \"\")`: This line of code replaces the substring `../input/test-wav-files-dl-sprint/test_files_wav/` with an empty string in the input `str`. This is essentially removing the specified prefix from the string.\n\n2. `.replace(\".wav\", \".mp3\")`: After removing the prefix in the previous step, this line replaces the substring `.wav` with `.mp3` in the remaining string. This is essentially changing the file extension of the audio file from WAV to MP3.\n\nThe purpose of this function seems to be converting file paths or keys of WAV audio files to corresponding MP3 file paths or keys, possibly for further processing or handling of the audio data.\n\nIt is important to note that modifying file paths or keys using string replacement can be error-prone, especially if the paths are not in the exact format expected by the function. Ensure that the input `str` matches the expected format, or consider adding error handling to handle unexpected inputs more gracefully. Additionally, if this function is used in a larger codebase, it's a good practice to choose a more descriptive name for the function than `post_process_keys` to reflect its specific purpose.\n\"\"\";","metadata":{"papermill":{"duration":0.019237,"end_time":"2023-07-26T05:38:41.076573","exception":false,"start_time":"2023-07-26T05:38:41.057336","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:17.18071Z","iopub.execute_input":"2023-08-01T02:26:17.181352Z","iopub.status.idle":"2023-08-01T02:26:17.19096Z","shell.execute_reply.started":"2023-08-01T02:26:17.18132Z","shell.execute_reply":"2023-08-01T02:26:17.190032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def directory_infer(audio_dir):\n    '''\n    infers on a directory that contains audio files\n    args:\n      audio_dir  : directory that contains some audio files <string>\n    returns:\n      a dataframe that contains 2 columns:\n        * path <string>\n        * sentence <string>\n    '''\n    # list all audio files\n\n    audio_paths=[audio_path for audio_path in tqdm(glob(os.path.join(audio_dir,\"*.*\")))]\n    files = os.listdir(\"/kaggle/input/bengaliai-speech/test_mp3s\")\n    paths = []\n    for i in files:\n        paths.append(i.split(\".\")[0])\n    sentences=[]\n    for idx in tqdm(range(0,len(audio_paths),BATCH_SIZE)):\n        batch_paths=audio_paths[idx:idx+BATCH_SIZE]\n        sentences+=batch_infer(batch_paths)\n        \n    df= pd.DataFrame({\"id\":paths,\"sentence\":sentences})\n    df.sentence= df.sentence.apply(lambda x:normalize(x))\n    #df.sentence= df.sentence.apply(lambda x:dari(x))\n    df['id'] = df['id'].apply(lambda x: post_process_keys(x))\n    \n    return df \n\"\"\"\nThe function `directory_infer(audio_dir)` performs inference on a directory that contains audio files. It processes the audio files in batches using the `batch_infer` function and returns the results as a DataFrame with two columns: \"id\" and \"sentence\".\n\nLet's break down the function step-by-step:\n\n1. `audio_paths = [audio_path for audio_path in tqdm(glob(os.path.join(audio_dir, \"*.*\")))]`: This line lists all the audio files in the specified `audio_dir` directory using the `glob` function. It filters all files with any extension (`*.*`) and stores their paths in the `audio_paths` list.\n\n2. `files = os.listdir(\"/kaggle/input/bengaliai-speech/test_mp3s\")`: This line seems to list all files in the directory \"/kaggle/input/bengaliai-speech/test_mp3s\" (hardcoded path). However, this line appears to be redundant and not directly related to the `audio_dir` parameter.\n\n3. `paths = []`: Initializes an empty list named `paths` to store the extracted \"id\" values from the filenames.\n\n4. `for i in files:`: This loop iterates through each filename in the `files` list (from step 2).\n\n5. `paths.append(i.split(\".\")[0])`: It splits each filename by the dot (.) and takes the first part to get the \"id\" value. The \"id\" values are then appended to the `paths` list.\n\n6. `sentences = []`: Initializes an empty list named `sentences` to store the predicted sentences from the ASR (Automatic Speech Recognition) model.\n\n7. `for idx in tqdm(range(0, len(audio_paths), BATCH_SIZE)):`: This loop iterates through the `audio_paths` list in batches of size `BATCH_SIZE` (assuming `BATCH_SIZE` is defined elsewhere).\n\n8. `batch_paths = audio_paths[idx:idx + BATCH_SIZE]`: Extracts a batch of audio file paths from `audio_paths`.\n\n9. `sentences += batch_infer(batch_paths)`: Calls the `batch_infer` function with the current batch of audio file paths and adds the predicted sentences to the `sentences` list.\n\n10. `df = pd.DataFrame({\"id\": paths, \"sentence\": sentences})`: Creates a DataFrame (`df`) using the \"id\" values from step 5 and the predicted sentences obtained from ASR in step 9.\n\n11. `df.sentence = df.sentence.apply(lambda x: normalize(x))`: Applies the `normalize` function to each sentence in the \"sentence\" column of the DataFrame. This function normalizes Bengali sentences, as explained in a previous response.\n\n12. `df['id'] = df['id'].apply(lambda x: post_process_keys(x))`: Applies the `post_process_keys` function to each \"id\" value in the DataFrame. This function modifies the \"id\" values, as explained in a previous response.\n\n13. `return df`: The function returns the DataFrame `df`, which contains the \"id\" and \"sentence\" columns with the processed data.\n\nIt is important to note that the provided code references `BATCH_SIZE`, which is not defined in the given snippet. For this code to work correctly, `BATCH_SIZE` should be defined earlier in the code or imported from an external module. Additionally, some parts of the code (e.g., the lines related to `files`) appear to be specific to a Kaggle environment and may need modification if used in a different context.\n\"\"\";","metadata":{"papermill":{"duration":0.024482,"end_time":"2023-07-26T05:38:41.112335","exception":false,"start_time":"2023-07-26T05:38:41.087853","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:17.194299Z","iopub.execute_input":"2023-08-01T02:26:17.196025Z","iopub.status.idle":"2023-08-01T02:26:17.220367Z","shell.execute_reply.started":"2023-08-01T02:26:17.195993Z","shell.execute_reply":"2023-08-01T02:26:17.2192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = directory_infer(TEST_DIRECTORY)\nsubmission.head()","metadata":{"papermill":{"duration":11.925018,"end_time":"2023-07-26T05:38:53.049024","exception":false,"start_time":"2023-07-26T05:38:41.124006","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:17.224615Z","iopub.execute_input":"2023-08-01T02:26:17.226877Z","iopub.status.idle":"2023-08-01T02:26:30.791527Z","shell.execute_reply.started":"2023-08-01T02:26:17.226827Z","shell.execute_reply":"2023-08-01T02:26:30.790543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check(sentence):\n    if len(sentence)==0:\n        return '।'\n    return sentence","metadata":{"papermill":{"duration":0.022292,"end_time":"2023-07-26T05:38:53.086055","exception":false,"start_time":"2023-07-26T05:38:53.063763","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:30.792936Z","iopub.execute_input":"2023-08-01T02:26:30.793815Z","iopub.status.idle":"2023-08-01T02:26:30.801588Z","shell.execute_reply.started":"2023-08-01T02:26:30.793778Z","shell.execute_reply":"2023-08-01T02:26:30.800581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.sentence = submission.sentence.apply(lambda x:check(x))","metadata":{"papermill":{"duration":0.020792,"end_time":"2023-07-26T05:38:53.11902","exception":false,"start_time":"2023-07-26T05:38:53.098228","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:30.802882Z","iopub.execute_input":"2023-08-01T02:26:30.803797Z","iopub.status.idle":"2023-08-01T02:26:30.812767Z","shell.execute_reply.started":"2023-08-01T02:26:30.803761Z","shell.execute_reply":"2023-08-01T02:26:30.811703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"papermill":{"duration":0.024592,"end_time":"2023-07-26T05:38:53.156483","exception":false,"start_time":"2023-07-26T05:38:53.131891","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-01T02:26:30.814152Z","iopub.execute_input":"2023-08-01T02:26:30.814773Z","iopub.status.idle":"2023-08-01T02:26:30.826249Z","shell.execute_reply.started":"2023-08-01T02:26:30.814738Z","shell.execute_reply":"2023-08-01T02:26:30.825248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### This notebook is a fork of [this notebook](https://www.kaggle.com/code/mbmmurad/lb-0-506-inference-w-previous-comp-winner-s-model/notebook).\n\n💗This notebook has made some annotations on the original code. If it is useful to you, please click like. Thank you!💗","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:34:25.678782Z","iopub.execute_input":"2023-07-31T14:34:25.679144Z","iopub.status.idle":"2023-07-31T14:34:25.694089Z","shell.execute_reply.started":"2023-07-31T14:34:25.679113Z","shell.execute_reply":"2023-07-31T14:34:25.69288Z"}}}]}