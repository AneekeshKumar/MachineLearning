{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "97jDW6dhYI0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "DDBIiBbGdjVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W00nRD-WTTXR",
        "outputId": "c33e29c7-6cd9-4b4f-8bbc-1c8ae16e008f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
            "Requirement already satisfied: noisereduce in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.7.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from noisereduce) (0.10.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->noisereduce) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->noisereduce) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->noisereduce) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->noisereduce) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->noisereduce) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->noisereduce) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->noisereduce) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->noisereduce) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->noisereduce) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->noisereduce) (2024.2.2)\n",
            "Requirement already satisfied: playsound in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "!pip install moviepy\n",
        "!pip install noisereduce\n",
        "!pip install playsound\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "import librosa\n",
        "import torch\n",
        "import tqdm\n",
        "# import torchaudio\n",
        "\n",
        "# from scipy.io import wavfile as wav\n",
        "# from scipy.io.wavfile import write\n",
        "# import sounddevice as sd\n",
        "# import soundfile as sf\n",
        "from playsound import playsound\n",
        "# import noisereduce as nr\n",
        "\n",
        "from scipy.io import wavfile\n",
        "import soundfile as sf\n",
        "import noisereduce as nr\n",
        "from pydub import AudioSegment, silence, effects"
      ],
      "metadata": {
        "id": "Ai_Nnm6F0IVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###Data Pre-processing\n",
        "- *Downloaded the video and Extracted Whole Audio*\n",
        "- *Did some Augmentations on the Raw Audio*\n",
        "---\n",
        "####Issues Faced\n",
        "  1. Had to convert from **Stereo to Mono**\n",
        "  2. **Reduced background noise** of People chattering and clapping. Also as the audio was recording of an announcement from the PA System.\n",
        "  3. As spoken on mic, the loudness was not equalised, hence, I had to **Normalise the audio.**\n",
        "  4.(Commented Out) Tried **removing silences** as it was Interfering with the Transcriptions, But was later taken care of by the model itself.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Python Modules used -*\n",
        "1. Moviepy\n",
        "2. noisereduce\n",
        "3. pydub\n",
        "4. librosa\n",
        "5. tqdm\n",
        "6. scipy.io -> wavfile*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PH43heh03OSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the video\n",
        "yt = YouTube('https://www.youtube.com/watch?v=Sby1uJ_NFIY')\n",
        "# stream = yt.streams.first()\n",
        "stream.download(filename='video.mp4')\n",
        "\n",
        "# Extract audio\n",
        "video = VideoFileClip(\"video.mp4\")\n",
        "audio = video.audio.subclip(0, 1575.06)\n",
        "audio.write_audiofile(\"audio.wav\")\n",
        "print(\"Length of audio in seconds = \", video.audio.duration /60, \"minutes\")"
      ],
      "metadata": {
        "id": "EkAf7waE0Nx3",
        "outputId": "93af097d-bd6d-4254-8169-d7395fcb276f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Length of audio in seconds =  26.250999999999998 minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert from stereo to mono\n",
        "print(\"Converting to mono...\")\n",
        "sound = AudioSegment.from_wav(\"audio.wav\")\n",
        "sound = sound.set_channels(1)\n",
        "speech1 = sound.export(\"audio_mono.wav\", format=\"wav\")\n",
        "print(\"---Done\")\n",
        "\n",
        "# load data\n",
        "rate, data = wavfile.read(speech1)\n",
        "\n",
        "# perform noise reduction\n",
        "print(\"Reducing Noise...\")\n",
        "reduced_noise = nr.reduce_noise(y=data, sr=rate, thresh_n_mult_nonstationary=2, stationary=False, use_torch=True)\n",
        "wavfile.write(\"noise_reduced_audio.wav\", rate, reduced_noise)\n",
        "print(\"---Done\")\n",
        "\n",
        "# Normalise Noise\n",
        "print(\"Normalising Noise...\")\n",
        "rawsound = AudioSegment.from_file(\"noise_reduced_audio.wav\", \"wav\")\n",
        "normalizedsound = effects.normalize(rawsound)\n",
        "normalizedsound.export(\"normalised_audio.wav\", format=\"wav\")\n",
        "print(\"---Done\")\n",
        "\n",
        "# # Split on silence\n",
        "# print(\"Splitting on Silence and removing the Silence...\")\n",
        "# sound = AudioSegment.from_wav(\"audio.wav\")\n",
        "# chunks = silence.split_on_silence(sound, min_silence_len=1000, silence_thresh=-16,keep_silence=100)\n",
        "# print(\"---Done\")\n",
        "\n",
        "# # Combine chunks\n",
        "# combined = AudioSegment.empty()\n",
        "# for chunk in chunks:\n",
        "#     combined += chunk\n",
        "# print(\"---Done chunking\")\n",
        "\n",
        "\n",
        "# # Save the processed audio\n",
        "# combined.export(\"silence_removed_audio.wav\", format=\"wav\")\n",
        "\n",
        "# # Save the processed audio\n",
        "# sf.write(\"finalised_audio.wav\", normalizedsound, rate)\n",
        "# print(\"----Audio sucessfully processed and saved.----\")"
      ],
      "metadata": {
        "id": "m10ZCJeQ0Pk_",
        "outputId": "93a0efa5-41ce-43e7-cc00-44cab34ec339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting to mono...\n",
            "---Done\n",
            "Reducing Noise...\n",
            "---Done\n",
            "Normalising Noise...\n",
            "---Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speech, rate = librosa.load(\"normalised_audio.wav\",sr=16000)\n",
        "# print(type(speech))"
      ],
      "metadata": {
        "id": "TA2wZsFq7LQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **My First Experimental Model - Wave2Vec2**\n",
        "\n",
        "- used for a basic implementation.\n",
        "- dropped the because the code was really lengthy and prone to a lot of errors, I made it errors free but still the next model provide better results hence...\n",
        "\n",
        "Following Implementations were performed by me.\n",
        "https://huggingface.co/docs/transformers/en/model_doc/wav2vec2\n",
        "https://www.analyticsvidhya.com/blog/2021/02/hugging-face-introduces-the-first-automatic-speech-recognition-model-wav2vec2/\n",
        "\n",
        "* Used the following implementation using ***`trellis matrix`*** for alignment of the transcriptions - https://pytorch.org/audio/stable/tutorials/forced_alignment_tutorial.html\n",
        "\n",
        "* For tackling problems of misinterpreting Indian Accent -\n",
        "https://medium.com/nerd-for-tech/indian-accent-speech-recognition-2d433eb7edac\n",
        "\n",
        "* Also tried finetuning the pretrained wav2vec2 model but didn't have enough resources or time. -\n",
        "    https://www.iitm.ac.in/donlab/tts/database.php\n",
        "    https://catalog.ldc.upenn.edu/LDC2019S11\n",
        "* Studied implementing Connectionist Temporal Classification - https://distill.pub/2017/ctc/\n",
        "* For Perceptual Linear Prediction (PLP) and Mel-frequency cepstral coefficients (MFCC) - https://jonathan-hui.medium.com/speech-recognition-feature-extraction-mfcc-plp-5455f5a69dd9\n",
        "\n",
        "For Inspirations -\n",
        "\n",
        "https://github.com/AdroitAnandAI/Indian-Accent-Speech-Recognition/tree/master\n",
        "https://discuss.huggingface.co/t/how-to-create-wav2vec2-with-language-model/12703\n",
        "https://github.com/flashlight/flashlight/blob/main/flashlight/app/asr/README.md\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nW___0mn7ONF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained Wav2Vec2 model and tokenizer\n",
        "tokenizer1 = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "model1 = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_GdIV77S4eK",
        "outputId": "5496ce38-ddc9-4124-d878-26b916803a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the chunk duration (e.g., 30 seconds)\n",
        "chunk_duration = 15  # in seconds\n",
        "chunk_samples = chunk_duration * rate\n",
        "\n",
        "# Split audio into chunks\n",
        "chunks1 = [speech[i:i + chunk_samples] for i in range(0, len(speech), chunk_samples)]\n",
        "input_values = tokenizer1(speech, return_tensors = 'pt').input_values"
      ],
      "metadata": {
        "id": "6-2NN5420XWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe each chunk\n",
        "transcriptions1 = []\n",
        "for chunk in chunks1:\n",
        "    input_values = tokenizer1(chunk, return_tensors='pt', padding='longest').input_values\n",
        "    with torch.no_grad():\n",
        "        logits = model1(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription1 = tokenizer1.decode(predicted_ids[0])\n",
        "    transcriptions1.append(transcription1)\n"
      ],
      "metadata": {
        "id": "mvhahs-DAEFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the transcriptions\n",
        "\n",
        "full_transcription_WAV2VEC2 = \" \".join(transcriptions1)\n",
        "print(full_transcription_WAV2VEC2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UrHFdUITrYQ",
        "outputId": "025b5d5f-4280-4ccc-8e77-7484335fd485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONGRATULATIONS TO YOU MISTER ROCKERBAN FOR THAT AKS OBOSTE TORNING UT OBERTE  AY EVERYBODY HOW ARE YOU AY NOT HEARING THIS AT ALL LIKE A POST LIE SHA AN EMPTY DOWNET OR SOMETHING LET'S HEAR IT ARE REGUISE THE WIG ALL RIGHT BETTER BE BECAUSE SA BE YOU HAVE A SUPA STAR GUESTIE AH YOU HERTH OF FORTY ONE MILLION DOLLARS A I DID GE ONSE IN IGNA SHE SAID AFTER THAT A SO O RIGNU ASK QUORTER WHAT FORTY MILLION DOLLARS SOHI BY THE END OF THIS CONVERSATION FOUQUET AHM BUT LET GET STARTED AH I WANT INTRODUCE THE VIC AND PRATHIUCHISCOPONDE WAS NAT HER AH WE WANTED TO STARD WITH A FLANG OF VIDIL AH OFF WHAT AM OPEN HATI DUS I ENCOURAGE ALL OF YOU TO GO AH TO THE WEBSIDE'S AROMBADIAI AND CHECK IT OUT AM BUT LET ME START BY INTRODUCING LE VIK AH WE MAKE AS A DEAR FRIEND AND A HE IS VERY VERY MODEST ON O OF THE MOST MODEST GUIDES THAT I KNOW BUT HIS PERSONAL TURN TO THE QUVINA YOU GOT A PIACTI FROM KANIMELEN YOU SATTRED AND SOLD A COMPANY TO MAGMA AND THE OBLECANDIPUT BAKTITIA FROM ROBOT IN THE VALLEY ON THE SAME DAY ACTUALLY AH AND EVVEN IN INDIA FOR THE LAST SIXTEEN YEARS AND A WHAT MOST PEOPLE DON NOIS AM YOUR JONAT ADA AM HE'S BEEN THIRTEEN YEAR SELFLESSLY ADADAR AM  DO REPORT OF HIM AH BUT HE WAS SERVED PIONEERY TECHNOLOGY MISSHIONERY BEHIND ADARN'T HE ALL TAKE FOR GRANTED TO DAY AM COOKED PLEASE GIVE IT OUT SERVE  HONESTLY WHEN PEOPLE WHEN I THINK OF SELFLESS SERVICE TRULY S LFLASOVIS A OYOLISTICAL TE VIC AND A SINCE THEN HE ALSO WAS AT THE IE FORBADAN AH WHICH WE ARE GONG TO TOUCH ON WITH PRATUSIUS OTHER COFOUNDER A PRATUSATA PIECTI VAMFA ITIACAZURIC AH HE WAS SIRTER IBIUMRI SEARGE WITH AT MICHOSOP RESEARCH PLAYING A KEYLOLD A AND A FACULTYA DIDEMADRAS A AND AT AIR FOR ABOUT IT SO THAT'S A LITTLE BLIEF INTRODUCTION ABOUT THEM THESE GUAYS ARE MODEST MODEST ENGINEERS A SO THEY DON'T DO THEY DON'T HAUNT A SO FORGIVE ME OTUTING DERHAN HA IN THIS CASE A BUT LET'S JUM PLAYTIN A ABOUT THE MONEY FUNDING WOT TO A MILLION BUCKS MAN THAT'S A LOT OF MONEY LI EVERY ONTEBUNE HERE TE SAME I HELL IT FAT THESE GUAS DO WHAT DID THEY NESTO S SE THO WRITE SUCH A BIG CHEQUE Y I THINK I THINK ITS SIR I THINK IT'S A TRIEND OFE NEW TRIEND OF WHAT'S GOING ON IN INTIA I THINK THAT FOR THE VERY FIRST TIME I THINK EINVESTORS HAVE LOOKED AT YONO LET'S TRY AND BUILL SOMETHING DECK OUT OF THE COUNTRY AND LET'S TRY TO FIG IT OUT HOW TO BUILT SOMETHING THERE'S A FOUNDATION OF DICNOLEGIA AN IND THAT'S REALLY WHAT'S WHAT'S REALLY EXCITING YOU KNOW AND I THINK THAT TER A ABOUT A YOU KNOW A ES AS ASER A WHILE I WAS M NTIONING FOR ABAST FIFTEEN YEARS I'VE BEEN KANDLE WORKY IN KAND O FINO A BOTH BERDIGED IN PUBLIC IN PLASTACCER AND AN AN ANKIND OF FUR A NON PROPRATE KIND OF THINGS AND BUT QUENTIS WOL THING OF GENRTIBEI CAME ABOUT I I YOU KNOW WA SAI LOOKI HOW CAN I ACTUALLY MAKE A DIFFERENCE IN THIS PASE AND I SAID MAYBE THIS IS THE OPPORTUNITY TO ACTUALLY COME OUT AND AND AN REALLY BEREIS SOMETHING ER YO AND AND THE ONLY WAY THAT REALIZE THAT YOU CAN DO THIS ACTUAL IN E ININ EA A PIPE SECTERAND I THINK THAT'S AND THEN E WHEN WE WENT OUT THERE AND WE SAID WE WANT TO BUILD SOMETHING WHICH IS A CONTINUATION RIGHT A MINUT FUNDAMENTALLY THE QUESTION IS ATHE REASON OF WHAT WE WANT TO TO IT SURVA MAY I IS WE WANT TO BASE CHEAKMATES AND TI AVAILABLE AN ACCESSIBLE TO THE PEOPLE IN THE COUNTRY AND THAT'S THAT'S THE INDEPENDENT AND WANT HE SAID THAT WE WANT TO DO THIS THERE WAS A RESIDENCE A IMPY INVESTMENT FABILITY AND I THINK IT'S IT'S A RESPONSIBILITY TO RARLY TO SHOW THAT E THAT'S SOMETHING LIKE THIS CAN BE PUT OUT OF INDIA SO WE SEE THAT AS AS AS AS CONFIDENCE AND A RESPONSIBILITY AND I ALSO HOPE IT'S A FRIEND THAT THAT FEEL THAT THERE ARE MANY MORE PEOPLE LIKE LIKE US WHO ARE BACKED BECAUSE IF YOU LOOK AT IT MAYBE IT'S A L CH NUMBER IN A AH YOU KNOW IN THE INDIAN CONTEXTS BUT IN THE GLOBAL CONTEXT I THINK THAT AT JUST THERE SHOULD BE MANY MANY MOREON FRUNNERS WHO ARE BACK TO DO THINGS IN INDIAS COME WE'LL COME BACK TO THE MIDIVOLANTIC NURSE AND OFF IS THE OGASKIA BARTA BATHE SHES A CUTREN SO WE WILNOT COME BACK TO THE QUESTION BUT AGAIN WHAT BE ONE MILLION DOLLARS ALL OF WHAT YOU SAID IN ALL TWO MILLION DOLLARS O COUNT THAT'S A GOOD ON OF MONEY FOR O SCATA WHICH IN ALL WHICH HAS NOT YET BUILT ANYTHING WHAT ARE YOUING TO DO WITH ALL THIS MONEY A A H AA A LIKE AN JALLAO OF THEM I IN THE HOW PERFECT SOLISION FOR THE POWHI I THINKE TE LAST WEEK I'VE GOT CUTS OF COTS BLORTS OF PEOPLE HA A L TELLIN ME HOW I CAN NOBOT BUT I KNOW YOU FOR SOKAS WE LANDE ESELTER I WOUL RATHER THE COE NO BBUBUT HONESTY I THINK A THE KEY THING IN THIS IS IS TO FOOTING TOGETHER AMAZINGY AND WE ACTUALLY HAVE AN AMAZING TY BUT BELIEVE THAT IT IS TALENT THAT WOLL PLY THIS KIND OF THING AND FOTIS IT IS TO GET A GET KEY TALENT AND OF COURSE THE OTHER THING IS COMPUTEPISIS A EXTREMELY A EXPENSIVE COMPUTE WISE TO ACTUALLY DO THESE KINDS OF THINGS AND I THINK THAT THOS UP A TO PRIMARY THINGS THAT THAT A YOU LO  USELES FOR RE  I AM AM COMPUTING IT MY OWN HEAD AS HANTREFORA ITALIAN TOQUET YOU HAVE LET PRETTY COTEVE EQUAL HOW MUCH VALUE PAINIS AXCO TOQUET WE YOU WONT TATCH SON E HER SHU AM WE LSTO WIT WHAT YOU GETS ACTUALLY BUILT WHAT I WHAT IS OPEN HAKI OPOWDY EXPLAIN OPENHATI MANY PEOPLE HER THE WHITE HATOF CAR NO MADDED SO I THINK OPENHAFI IS SOFUTZOFESTIVALL RIGHT WE COME FROM A PERSONALLY COUT FROM THE OPEN SORCE I KOSTEMENT AN AN ALSO FROM THE DIPIAI I KOSTE SO WE BELIEVE THAT FOR THIS TO WHAT WE NEED THE ECUSSTEN AH TO BE SUCCESSFUL AND AS A RESULT OF THAT ONE OF THE FIRST THINGS WE DID WAS HE THERE ARE THESE OPEN SORTS LARGE LANGUAGE MODELS THAT EXIST STRIGHT IMEAN EVERYBODY KNOWS ABOUT THE LAMAR AMILY FOM MADAM THEYOLD SUME IN THERTHER OTHERS LIKE MISS TRAL TRAPON BUNCH OF OPENSORTS A A INO LARGE LANGUAGE MODELS AND THEN WE SAY IS THERE ANYWAY THAT THEY CAN EXISTIN OPENSOS MODEL AND TEACH IT LIKE WHIT SKIP TRIGHT A MIN AND THAT IS REALLY THE AH YOU KNOW WHAT ME TIS SY WHAT YO SAID THAT CAN WE DO SOMETHING LIKE THAT AND IS THIS A YOU NO RENIT FUGAL WAY OFF OFF ACTALY AH YOU KNOW MAKING A BOTTLES AH YOU KNOW A WORK IN IN IN DIVERSE LANGUAGES BECAUSE THE TRUTH IS STILL TO DAY AMETI FILOCATTHE AMOUNT OF A DATE I ACKNOWLEDGE IT STILL ENGLISH DOMINATES MYSTICS AND AND AND I THINK THAT HOW DO YOU ACTUALLY TAKE AND MAKE IT UNDERSTANDING IN LANGUAGE UND STANDING YEN CONFEXED AND ALL OF THOSE THINGS IT INACTUALLY E IN AN EFFICIENT WAY AND THEREFORE THIS WAS AN ATTEMPT TO THAT AN ANISE OPENHATI IS A INOIS ISCANTI BESMOTHE LAMA A SEVEN BILLION MODEL BUT WI WIT A DESEIT EN MORE MODELS AND DIFFERENT LANGUAGES CONCISES AND THINGS LIKE THAT AS PART OF THIS AS PART OF THIS SERIES AND AND OF COURSE YOU KNOW WE WILL BEL BUILDING FURTHER BODLS ON THOSE AND DOING OTHER THINGS TO TO ACTUALLY AND WE'LL ALSO HAVE ANY POINTS THAT PEOPLE CAN US SO THAF IT IS NOT IT'S DEPRITY A YU KNOW SOMETHING THAT PUGENT CAN A GET USE TWO THINGS AND BE THAT'S THAT'S THE ESSENCE OF OF A WHAT AZOPENHAV GUES SO WHAT DOES IT MEAN TO PEOPLE AN AUDIENCE HERE TOR EITHER BGERONT STARTAT WAT BUSINESS OR A AR OUR DEVELOPERS HOW SHOULD THEY LOOK AT MIETE I ASEED HIMSELF NOT NO YE NOT O ITHINK I THINK THE WAY YOU LOOK AT IS AT ME WE ARE ONE OF THE IMPORTANT THINGS THAT WE ARE DOING IS WE NOT JUST A B DING MODELS AH WE ARE ALSO REBUILDING AA PLATFORM A PLATFORM FOR DEVELOPERS WHERE CAN ACTUALLY USE A A COMBINATION OF VARIOUS DIFFERENT KINDS OF MODELS SUM WHICH ARE FROMAS SUMK TO OPEN SOR SUME WHICH MAY NOT WOPEN SUC AN ACTU HE TO AT TO POOL TOGETHER AND FIGURE OUT HOW YO DEPLY AR IN ALL PA GENIT EIR APPLIGATIONS AT SKALE AND UNDERSTAND AND VALUATE THEIR PERFORMANCE IN AN EFFICIENT MANNER AND THAT'S SOMETHING THAT WE'RE PLANNING TO DO IT THIS ENENO TISPLA POMIS NOTE IN  THE NEXT SOBLEMONTHS WILL BE COMING OUT THERE BE AVAILABLE TO DEVELOP US BUT OF COURSE GHOSE WHO WANT TO START WITH THE OPONSORCE HER THINGS AN ANHACKDWITHET A POS PLEASE GO AHEAD THAT AS WELL THAT'S THAT'S PHENOMENAL COM BUT HOW DOES IT COME PAR TO OPEN THE ER ITSELF O ORGOUGALY SEE AT LEAST THE THINGS THAT WE ARE DOING NOW WRIGHT ABET ONE OF THE THINGS THAT WHEN WE TAUGHT ABOUT THE TEBUILDING SARA EXCEPT WE WANT TO BUILD A A FULLS THACT GENTETE THE ACCOMPANYAN RY DIFFERENT PEOPLE OF AND IN OUR UNDERSTANDING OF TE STACK IS THAT WE NEED TO KNOW HOW TO TRAIN MODES FROM SCRATCH WE NEED TO KNOW HOW TO KIND OF FIGURE OUT HOW TO DEPLY MODELS SULPRIAL WELL USCASUS AND WE NEED O PLAY THE CO SYSTEM TO MAKE SURE THAT WE CAN ACTUALLY DEPLY A POPULATION SKILL A AAPPLIGATIONS RIHTS'LL BE WHAT WE THINK AFOUT ALL OF THESE PIGS BUT STILL THE MODELS FOET O POOL OUT ARE NO FAIRLY SMALL MODELS TERFER MALL MODOS RIGHT THERE SEVEN TO MILLIA TO SEVEN BILLIAN KIND OF RANGE BITOT WORK WHALL THESE MODALS LIKE OPENY I AND AT LAROS MUCH BIGGER MATOS RIGT BUT WE WANT TO QUI QUIT WE WANT TO UNDERSTAND ITES ANT BE ABLE TO BILL THAT M USSLE TO DO ALL OF THESE THINGS A TO TO PWICKET TO MAKE IT AVAILABLE PEOPLE NOW GHOS SMORTI SAR I AM IN AS AS A SAD EH YOU KNOW I THINK THAT THERE IS SPACE FOR ALL OF THOSE THINGS AND I THINK ESWHEN ASTRY THAT WORTH TALKING ABOUT ELL ER IN THE DAY ARE WE BELIEVE THAT THESE SMALLER MODELS CANBOO A BERRY AN MANY MANY KIND OF DOBIAN THE TYPIC PLASS EXTREMELY WELL PROPERO EVEN BETTER THAN THE N THE LARGER MODELS AND THAT IS LATLY ONE OF THE KI ERIAZAN AND SO THAT FOR THE VALUE OF THESE KINDS OF THINGS RIGHT WE'RE NOT AIMING IN THESE MOSETA BOTLES TO TO BUILD ANY AG I RIGHT THAT'S NOTTIR BOIK OUR GOLL IS TO MAKE THINGS THAT WORK EXTREMELY WELL FOR I DOMEAN SPECIFIC USECASES OR AR IN CESE AACCESSIBILITY TO LANGUAGE AND AN OROPOSPIT OBVIOUSLY ALL OF THIS UNIQUE TO ITIA WHAT IS UNIQUE ABOUT IT HERE MOLIK WHAT IS IS ANYTHING SPECIAL IN OUR EQUAL SYSTEM THAT THAT MAKES A SMALL MODELIS COCUSED WITH INDIAN LANGUAGES BETTER WHAT MONSER DE FRA POES SO I THINK THAT AMIN DERAR QUI TE FWO THINGS THAT ARE UNIQUE OF OUR UDIERI A THE FIRST THING IS I THINK THAT PIERRA WWIS FIRST LATIONS THE FOR I THINK WIS HAS TO BE THE FOR TO DOING THINGS A THE OTHER THING OF COURSE INDIA IS A EXTREMEL EH IT'S ACOST CONCIOUS COUNTRY FORT FROM FROM PROMA FROM ACOSPE SPECTOR NOW THERE THE I WOLD SAY THAT THERE ARE LOTS OF INTERESTIN USECASES WHERE YOU CAN USE OR A I AND THE COSS STRUCTTURE WORKS THAT WINT WENT W DEPENDING ON YOUR APPLICATION BUT WHEN YOU WANT TO SKILL THINGS TO A MASSIVE LEVEL AND MAKE IT WORK THEN THEN YOU HAVE TO FIGURE OUT HOW SMALL MINS WORK SO THAT'S SOMETHING THAT IS A ALSO SPECIFIC TO YE THE THIRD TING WHICH IS SPECIF DIA IS REALLY THE SUCCESS THAT INDIA HAS HAD IN BUILDING ALL THIS DIGID REPUBLICAN FRORSTRUCTURE WHEN YOU ADD THE AILER ON TOP OF IT THEN YOU CAN ACTUALLY GET DRAMATIC A ER YOU KNOW A DRAMATIC I THINK MULTIPLICATIVE E MENDORIAL EFFECTS BASED ON DOING THINGS LIKE THAT'S A PHENOMENAL POINT LAK YOU KNOWITS LIKE DIPIEI TO THE POWER OF THE AI ALMOST SOMEWAYS 'SA PART OF OTHER BUILDING OTHER NO BETTER PERSON THAN YOU I'M SO IN SOMEMODY WHAT I'M HEARING IS SMALL MODELS A SPECIALIZED WITH TRAINED WITH DICK SPECIFIC LANGUAGE DATA SUITED FOR INDIAN PROBLEMS AT THA COMPELLING COSSPOINT A WILL BE SUITED FOR A TRANSOLVING SOME WORLD AUTOMOUTOCVAKERS OR SOME COMPLEX PROBLEM RESOLVING COME BASIC PROBLEMS SPE ETICULY FOLCUS WITH ONVOICE OF PRACTICAL LANGUAGES THAT IS WHAT YOU SEE AS THE FUTURE AM I BATAFICING THE SKELETO NOT YET SO I THINK THAT CERTAINLY I MEAN A VOICE AND ANYON LANGUIGE IS UTTER UTOR AN IMPORTANT PART OSTRATEGY BUT WE WILL BE BUILDING AT YOUR ACCUSTOMED ODELS TO FAULT VARIOUS OTHER KINDS OF POBLERS AS WELL PRAY THAT'S NOT JUST LIMITED TO A I THINK INDIFFERENT DOMAINS WERE HEATED OVR E DOMAINS MAKING BELIEF TATES BASED ON UNIQUE DATER THAT THER ENTERPRISES HAVE INSO THAT'S THAT SOMETHING THAT PILOSA LOOKAT FAR ENOUGH SO COMING BACK TO THE I THE ELEPHANT IN THE ROO NO NO CONETTENDED WITH OPEN HAT HEAT AH WHAT ABOUT BABISHETE VALENTA CRUTRIM WHAT DOES YOUR TAKE ON THAT I THINK IT'S CLEAT I THINK IT'S ABSENCE IT'S WONDERFUL RATE I MEAN THE FACT THAT A TI TI EGNOLIT E EYE IS SO IMPORTANT THAT WE LEED PULTIBLE PEOPLE WORKING ON IT THE FACT THAT THERE ARE OTHER PEOPLE THINKING IS ACTUALLY VALIDIS THAT THIS IS AN IMPORTANT PROBLEM TO BE SOUGHT AND AND I THINK BETTE BETTER AN WE NEED EVERYBODY TO COME TOGETHER AND DO THAT SO I REALLY WELCOME THAT I THINK ITS ITS GREAT AND I THINK THAT ER THEY'LL BE DIFFERENT PEOPLE PLE HAVE DIFFERENT PATES AS TO HOW TO SOLVE THIS KIND OF PROBLEM AND AND HOPEFULLY AS A RESULT OF THAT THE ENTIRY KOSISTONE BENEFITS IV WONE MORE QUESTION AND THEN I WANT TO TALK ABOUT SOME OF THE PREDICTIONS THAT YOU BORGE MAN SOBEVIC AH I USUALLY ASK PEOPLE ABOUT WHAT D YOU THINK THE FUTURE'LL BE AND EVERYBODY USUALLY HEDGES AH I ASK VIG WHAT DO YOU THIK IS GOING TO HAPPEN AH BITE DECEMBER TWENTY TWENTY FOURTH WH R DO YOU THINK SITTING IN THIS ROOM ONE YEAR LATER WE CAN EXPECT AND HE MADE THREE BOLD CRETICTIONS SO I WON'T TALK WITH THAT BEFORE THAT HA ONE LAST QUESTION AM WHAT ARE THE TAP THREE APPLIGATIONS THAT YOU THINK AR RELEVATE FOR INDIA AM YOU WOLD TREAT THE TALWARD MEDICAL WH WRITTEN OF ANY FIX HOMETY WHAT IS WATS YO WANTED TO GIVE THE TOP TO THE APSAD WORIN YAPO EI SO AMENITE I THINK BETTER AS SAID THINGS LIKE A EDUCATION AT MECALARCHIER E IDIAS WHERE WERE WER WHERE I THINK THAT THINGS CAT CAN BE LEMINI THE WHOLE IDEA OF ALL THIS KIND OF A THE DEEP YY ASPECT OF IT IS ANOTHER MAJOR APPLICATION WHERE THINGS CAN HAPPEN IN AND HERE I'M GOT BUT ANTYSMESIFIQUA AND I THINK THE WHOME I NEW ITS PUD ALSO TALKED ABOUT WAS THE THE A CONCEPT OF SOFT CLARE I AND I THINK THAT AND AND CLEARLY WE HAVE A VERY LARGE SHOCKWERD INDUSTRIAN AND HOW TO HE IMAGINE THOSE THINGS IF IS CONFEX DESOSE SOMETHING THAT'S COULD  FER ENOUGH AH I'LL GUESS READY FOR INTER CLAD ONES OLD PREDICTIONS YES NO I'M NOT HEARING IT YER SIR THIS IS LIKE A BIG DEAL HE'S THAT ONE OF THE SMARTEST GUIDES THAT I KNOW YOU AUGT TO MAKE THREE PREDICTIONS BELON TO HEAR IT 'R ALL RIGHT HELLO I ASKED HIM MA'AM WHAT DO YOU THINK IN OL HERE LATER WHAT ATE O YOU THINK YOU CAN EXPECT A HONEY CIME UP WITH THREETINGS THAT USUALLY PEOPLE FEEL VERY BLAD SERS AN LAST QUESTION LIKE THIS CAUSE THEY DON'T WANT TO BE CAUT ROF NOT TE BAK MAKE HIS BOLD AM SO HE MAY SECELY SAT THREE TINGS AND I WANT TO LIST OUT THE TREETINGS AND AN A ASK HIM ABOUT IT SO NUMMA ONE HE SAYS SA I WILL PREFER TO TALK ABOUT AUTERMATED CUSTOMER SERVICE THAN A REAL PERSON IT'S BECAUSE THEY GIVE ME A BETTER ANSWER THAT IS THE VIGRAGWAN'S PREDICTION OF A ONE SO BUR TWO IS THAT WHEN EVERYBODY IS TALKING ABOUT A G P U SHOTTAGE AM THE VIGE PREDICTS O THE BIA DIT GIPO GLUTTIN IT YE ETHINGS THALL BE TOO MUCH IME DETAN SO GO ON A SHART AND MEDIA STOP SAID LETANS AM AT NUMBE THREE WHICH WAS EXTREMELY UNEXPECTED HE SAID SOME COMPANIES WILL SUDDENLY DIE LIVIC THESE ARE MADWHAT I EXPECT AH SO THE ONE OF A QUICK YY TAO POT A EAT OF THET WIFE TWITES JUST THEA HOUR HE SAT AT AND TROW THE HERS SOLT OF SORD INTO IT BESIDES I DON'T THINK I QUITE SAID IT THE RA BET THITER WHILE I'S OUT A HITING BUT PUT IT WAT IT'S INTERESTING  BUT I THINK THE FIRST THING A A THAT WE SAID IS I THINK THAT AAND AND I DON'T THINK THAT THISIS I THINK THET THERE WILL COME A TIME WHEN A YOU KNOW A IN IN ERIAS OF CUSTOMER SERVICE ET CETERA WHEN YOU WANT TO DO SOMETHING VERY SPECIFIC TO DAY YOU KNOW WHEN YOU CALLER WHEN YOU CALL SOME KIND OF A PART YOU ARE CLEANED UP YOU MOSTLY TRY TO DISCONNECT THE BALL OR ORGUNO  YOU'RE EXTREMELY A UPSET TTYOU OPIN TOAVON BUT I THINK THAT THERE WILL COME A TIME ANANANIPREDIKE IS SOONER THAN LATER THAT YOU'LL ACTUALLY GET BETTER RESPONSES AH FROM THE BOT THAN WHAT THE HUMAN A REPRESENTATIVE THAT KES BE AVARAGE OVEN REPRESENTATIVE THAT PEOPLE TALK TO COULD GIVE AND I THINK THAT THAT'S JUST THE  TRY TO SAT THAT THAT THAT THERE WILL COME A TIME WHERE YOU KNOW IT'S NOT A HUMOR YOU'RE TALKING TO BUT IT'S PROBABLY MORE LIKELY TO SOLVE YOUR INDENT  THAN THAT THAN THE HUNIPESSETOR THAT'S TAT A SOMETHING THAT THAT TH T TER ATHAT I THINK THAT TE GOOD HAPPEN EFNETLY CONTRABORCHELL YARD AH WE'L LET IT GO WHAT ABOUT THE JEP OU GLUTT NO GES I I DON'T THINK THAT SO I THINK  THE FACT THAT THERE IS A TREMENDOUS A SHORTAGE LIGKT NOW I THINK THAT TROTTET WIT PES BECAUSE THAT IS HOW THE CYCHES OF THINGS SCORE RIGHT WHEN WHEN HE WENTED IN O ITHINK THE FACT THAT THERE WAS SUCH A SEVERE SHORTES LAST YER YOU KNOW PATENTLY POSD A NUMBER OF THE FIT PLAYER STO TORAPATID B ARIOUS KINDS OF FORMS AND I THINK THA THAT TAT THAT'LL ALWAYS GO IN A CYCLE BUT YOU MAY WELL FIND OUT THAT THERE ARE MANY MANY MORE INTERESTING PROBLEMS THAT PEOPLE HER BRUSOLVE I'M II I STILL A REMEMBER A GENOL A WE WERE AT AT AT ATE GENIA EVENT IN BACK LORAT WE WERE TALKING TO PEOPLE ET WE SAID YOU KNOW HOW MANY PEOPLE HAVE ACCESS TO YOU KNOW AFOR EIGHT HUNDRED CESPOD THE QUESTION THAT HAD ASKED AND NOBODY IN THE ROOM AND THESE ARE ALL EXTREMELY ENTHUSIASTIC GENE AND NOBODY HAD ACTS AND I THINK THAT THING IS GOING TO CHANGE YOU WILL BE ABLE TO GET KINDS OF THINGS AND PEOPLE WHO WANT TO PACK AND DO THINGS WILL HAVE ACCESS TO DO THINGS AT IN IN WITHOUT YOU KNOW AHAVIC THE WRITER YOU NO A MADE CHECK CH LIVIG IS ALSO A SEMI CATECK TO DIE BEFORE HE WENT ITO ADARO I WOULD TAKE HIS PREDICTIONS VER YOU SELIOUS TENK SO I KNOW WHAT I OP O ILL SELL MY IMMEDIATE STOCK ANR I WOULD NOT DO THAT BUT THAT'S NOT WHAT I SAIY O'LL BLAME YOU FIRST I EA I BUT THE THIRD ONE IS PRETTY STRANGE HAH IT OLL COMPANIES A BARN COMPANYES DIE BUT YOU SAID SOME COMPANIS WILL SUDDENLY DIE WHAT DOES THAT MEAN NOR I THINK SEE I THINK THE THE INTERESTING THING IS AND I THINK THAT IF IIT COMES BACK WITH THE FUNDAMENTAL NATURE OF THE AIR A I IS A POOLFRIGHT AND YOU'LL HAVE TO USE THAT AND YOU HAVE TO USE THAT WITH IT YOUR BUSINESS PROCESS RIGHT AND HOW A I USE AND SO AND WHAT'S GOING TO HAPPEN IS THAT MINUT I THINK THIS IS TRUE A WITE A WIT YOU KNOW IT BEEN SOMEWHAT SET UP INTOMS OF YOU PEOPLE THEY SAID THAT THE PEOPLE WHO NEVERIS E I WILL BE WILL WILC MORE EFFECTIVE THAN THOSE WHO DON'T LEVERESKA AND THAT WILL SPEAK FOR ORGANIZATIONS ALSO ORGANI SATIONS THAT LEVERAGE EI IN FUNDAMENTI IN THEIR POOR BUSINESS POSTIES WILL BE MORE EFFECTIVE THAN THOSE WHO DON'T RIGHT AND I THINK THAT'S THE THING AND YOU WON'T KNOW THE DIFFERENCE UNTIL ONE DAY IT BECOMES TOO OBVIOUS AND IT'LL BE TOO IT AND I THINK THAT'S THE REASON WHY EVERYBODY MEADS TO THINK ABOUT WHAT IT MEANS FOT YOUR BUSINESS BECAUSE YOU EVERYTHING WILL BE FINE EVERYTHING WILL BE FIND THAN ONE DAY SOMEBODY IN YOR EH EITHER EITHER'S TILLY OR COMPETIT YOUR SPACE OF SOMETHING GRAND NEW COMING INTO YOUR SPACE WILL BEIMAGINING YOUR BUSINESS PROCESS COMPLETELY AND AT THAT STAGE YOU'LL FIND THAT IT'S E NO IT SIR IT'S A VERY BIG A VERY TALL  HERO A MOUNTAIN TO PLAN AND THAT'S WHY I THINK IT'S PORTANT FOR BOTH PEOPLE AND ENITIES TO THINK ABOUT HOW THEY WILL A OUKNO DAY THEY WILL UPBAID THEMSELVES OR THEY WILL BORDIFY THEM WHOS PUSS IS TUN IN ATOUR THAT'S A VERY NOISE ACADEN WHO EVERYBODY HARWAS ON OR BUSINESS SHOULD REALLY THINK A OTTED BECAUSE LIFE WILL BE SIM AND THEN SUDDENLY SUDDENLY SOMETHING WILL INO THEN   BE A STEP CHANGE AM TE MAKE OUT FEW MORE QUESTIONS BUT I SURE THE AUDIENCE AS A LOT OF QUESTIONS FOR YOU SO A HURRY DINONTIM NOKING SO AM DA'S LOOKING A LOT OF QUESTIONS SO LOP TO AH IS IT A MITE THAT BEGAN PASSO THANK YOU MY NAME IS CARTIC I VOT FORA A A HIP SERVICE INUSTRY SO YOURE SEEING THAT YOU'RE WALKING ON AH AH ELLELEM ARSORI SAS FIND YOUN DE LE LEM ON TOP OF LAMA MY BASY QUESTION FUNDAMENTAL GOSHELIS WE DON'T HAVE A FIND AM FOUNDATIONAL MPORTER FOR INDIA MOST OF Y MODALS AR BUSICALLY ISING AR ENGLISH AR THE DOSCANOFTINS FOR EXAMPLE EN AN ANDREW WAS TALKING ABOUT THE AR DOCCONAIZER SOMETHING EXCITEMENT SO ARE YOU WORKING ON ANYTHING LIKE THAT ARE YOU WE WANT TO USE BOSLI THE EXISTING MORTLS AND ON ON TOP OCKET ARE YOU GOING TOLOSK TISOLD QUESTION YOUR A CHERRYQUESTION WORT HOW COLT YOU HAV THO ITINK GREOF THE INTERESTING THING IS THAT IF YOU LOOK AT AN HAVACLYABLOG ON THIS ON O REP SITE I THING ONE OF THE THINGS THAT YO ACTUALLY BILT ECASTOMISE TOKONITER WHICH ACTUALLY FUNDAMENTALLY CHANGES THE COSTO SOME OF THESE GENERATIONS INDITE LANGUAGES AND AND I THINK THAT YERE WILL NOT JUST FIND YOU WHERE ACTUALLY WE ARE BEVERAGING THE EXNIS PETENNY WE AD BE WAT'S KNOWN AS CONTINUAL PRETRAINING WHICH ACTUALLY BUT HAVE YOU SAID THAT YOU KNOW AH I THINK THAT AT WHENCE YE HAVE TO FIGURE OUT WHERE IS THE DETAIL TO TRAIN AN EXTRIMIALIZED MORTOR FROM SPATCH AND SOME OF THOSE THINGS ARE THINGS WHICH WILL HAPPEN AH O WHAT TIE BUT I THINK BETTER AHI THINK THATER YES I THINK THAT WE WILL BE PUDDLING VARIOUS KINDS OF THINGS BUT THE INTERESTING THING IS THAT IF I WANT TO CHEATE THE ACCESSIBILITY BROWNED WITH AN EXISTING OPEN SOCH MODL HOW DO I DO THAT AND THAT'S THE PROBLEM THAT WE HAVE ARD THAT WE THINK WE HAVE SORVED END AND THIS WOULD BE THE HEART OF A SO SIXCIDELY WELL EXPLAINED TO THE BLOGEVER I COULD UNDERSTAND IT SO I A E SHANT I WROTE FOR A FIT TOC MY QUESTION IS LE LIKE CHINA WE NEVER HEARD A CONSUMOFIZING ABPICATION A COMING OUT FROM MEDIA AND IN BEPRONVEPU KEPTUENON WHY DO YOU THINK IT  BE DIFFERENT TO SPAMIN LAKE A EE BECAUSE E BUILD E T B I AND OTHER THINGS WILL TIS AF THE SAME PURPOSE BUT TO GREAT FIR WOR DID IT JOINO OR ROOTING LIKE ENAGH BECAUSE AA IVEN STREAT SECTOR NO OUTSIDE COUNTRY CAN B ORGIN NASA PROJECTS MAYBE COLGOTEGOTAT FUGURTO TET WATEDE IS THE MOTHER FOR ANIMATE COMPANY SO I DOLT RITHINK I THINK I THINK THAT THAT THE QUESTION IS ER I DON'T KNOW HE ANSWERED HIS QUESTIONS RIGHT ON ME   MY AN I THINK THAT ER IT'S A DIFFICULT PATE BUT I DO BELIEVE AND AS I LIDE REPEATING THAT THE COMBENTORIAL EFFECT OF THE BLOSING GENEIT A BODSKALE IN ADDITION INTO ALONG WITH THE DIVII WORTH TA PIPLANITYVIA WILL HAVE PEOPLE AND I AND I THINK THAT OU IEN ER IT IS E THE THE INDENT IS THAT PEOPLE MEED TO BE ABLE TO USE IT AND THEY WILL VOTE QUIT THINGS THAT ARE MUSIFUL FOR THEM AND IF THAT DOESN'T HA N  YOU ARE RIGHT THAT THAT I THINK THA TE  WE HAVE TO FIGURE OUT WHAT IS THE MECHANISM OF THE DEBRI OF ABSIDE A BIT AN IN BOHOO WELL DO ITDIANS CONSUME NOT ATDESIBATE AMP SO STUADY BUT WE ARE OUT OF TIME TE IT WILL E OUTSIDER SO AR HE WILL BE ABLE TO ASK THE PURSUIT OF HEMPER A KENE ENE DIST TIGUAN LAST YER THANK YOU THANK YOU I HAVE MANISH KUTARI I AM FROM IAS YER BISA SCHOOL GUD THAT INT GOT A CHANCE TO ASK YOU THIS QUESTION YUDING LANSTIME THE VIT O FEW OF OUR EDUCATION IS FOVEVER TALKING ABOUT AT WE VER THERE WAS ONE FROM SCHOOL AND BIERRE THRON THE BI INSTITUTIONS WE WERE THINKING OF THESE PRESENT GENERATIONS HOW DO WE GET THEM INTO WHAT YOU ARE DOING THERE IS ONE THING THAT THEY HAVE MED REGULARLY THAT THE C ONCENTRATIONS THAT THEY ARE WORKING ON BUT ARTIFICIAL INTELLIGENCE AND GETTING INTO THIS GETTING THEM INTO THEIR ACADEMICS AND MICKING THEM APART OF IT IS VERY IMPORTANT INCLUDING THE TRAINERS WHO TRAIN THEM MAKING THEM FUTURE READY TO WHAT YOU ARE DOING IS AMAZING AND THE SPEED THAT WITICH IS GROWING IT IS CALLING FOR A LOT OF FUR DRAINING THAT MEENS TO BE DONE CAN YOU FROM YOUR ANGLE TOLS O LIGHT ON HOW WE COULD MAKE THE FUTURE READY HOW THESE PEOPLE WHO RE WHO OUR MANAGEMENT GRADUATES AND FROM SCHOOLS WHO AR COMING DOUT HOW DO WE GET INTO THIS PART OF TECHNOLOGY THAT YOU SPOKE ABOUT COUS THIS IS MISSUS LYLIA CHALLENGE BECAUSE I THINK EVERY ONE WILL MEET TO UNDERSTAND AT SOME LEVEL A WHAT BISTACHKNOWLEDGMET DOES AND I THINK THAT THE WE HAVE TO RETHI HOW WE GET EVERY ONE A INTO THIS CONDETIS TAT THIS KIND OF EDUCATION HAS YET MANY DIFFERENT CLEVER SIGHTS THAT A A FROM A POOR SET OF HAVING PEOPLE WHO ARE EXTREMELY GOOD AAAD AT SOMET AND THERE YOU DON'T GAS MANY BUT TEN THET AR PASITY VAST SNAPPERS OF PEOPLE LOOK CAND ACTUALLY LEVERATES THESE GOODS BY THE WAY THE MOST IMPORTANT THING ABOUT AND IRIBY AT'S PART OF WHAT WEEKS TENELA LEV INTERESTING IS THAT HOW YOU USE IT AH YOUR YORGORGOR YOU'RE MY LEDS VERHE PI AT AND TO UNDERSTAND HOW TO ACT DELIVERATE THIS IN AN INTERESTING WAY IS SOMETHING THAT WE HAVE TO WIDLY AH IT TEATS MANY MANY PEOPLE AN AN AN AND BECAUSE IT IN ASKING THE ERYOU KNOW THINGS THE RIGHT WA AND AND HAVING THE RIGHT AND OF APPLICATIONS WILL MAKE A O GIPETS TO HOW PEOPLE ARE AN AH THANKEE THANK YOU VERY MUCH WILL MAK ALT VERY GOOD LUCK TO SARVOM AT GOOD LUCK TO IDIATIC AS WOL BEA NOT RIGHT ON RESORDET THANK THANKS BOLLA THANK YE MISTER RAGIVAN \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_transcription(transcription, max_chunk_length=512):\n",
        "    words = transcription.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for word in words:\n",
        "        current_chunk.append(word)\n",
        "        # If adding the next word exceeds the max length, start a new chunk\n",
        "        if len(\" \".join(current_chunk)) > max_chunk_length:\n",
        "            # Join the current chunk into a string and add it to the list of chunks\n",
        "            chunks.append(\" \".join(current_chunk[:-1]))\n",
        "            # Start a new chunk with the last word\n",
        "            current_chunk = [current_chunk[-1]]\n",
        "\n",
        "    # Add any remaining words as the last chunk\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "chunk_transcription(full_transcription_WAV2VEC2, max_chunk_length=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ0OYWNBV7wg",
        "outputId": "f0a17144-025d-4f86-811e-b680b53c1eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"CONGRATULATIONS TO YOU MISTER ROCKERBAN FOR THAT AKS OBOSTE TORNING UT OBERTE AY EVERYBODY HOW ARE YOU AY NOT HEARING THIS AT ALL LIKE A POST LIE SHA AN EMPTY DOWNET OR SOMETHING LET'S HEAR IT ARE REGUISE THE WIG ALL RIGHT BETTER BE BECAUSE SA BE YOU HAVE A SUPA STAR GUESTIE AH YOU HERTH OF FORTY ONE MILLION DOLLARS A I DID GE ONSE IN IGNA SHE SAID AFTER THAT A SO O RIGNU ASK QUORTER WHAT FORTY MILLION DOLLARS SOHI BY THE END OF THIS CONVERSATION FOUQUET AHM BUT LET GET STARTED AH I WANT INTRODUCE THE VIC\",\n",
              " \"AND PRATHIUCHISCOPONDE WAS NAT HER AH WE WANTED TO STARD WITH A FLANG OF VIDIL AH OFF WHAT AM OPEN HATI DUS I ENCOURAGE ALL OF YOU TO GO AH TO THE WEBSIDE'S AROMBADIAI AND CHECK IT OUT AM BUT LET ME START BY INTRODUCING LE VIK AH WE MAKE AS A DEAR FRIEND AND A HE IS VERY VERY MODEST ON O OF THE MOST MODEST GUIDES THAT I KNOW BUT HIS PERSONAL TURN TO THE QUVINA YOU GOT A PIACTI FROM KANIMELEN YOU SATTRED AND SOLD A COMPANY TO MAGMA AND THE OBLECANDIPUT BAKTITIA FROM ROBOT IN THE VALLEY ON THE SAME DAY\",\n",
              " \"ACTUALLY AH AND EVVEN IN INDIA FOR THE LAST SIXTEEN YEARS AND A WHAT MOST PEOPLE DON NOIS AM YOUR JONAT ADA AM HE'S BEEN THIRTEEN YEAR SELFLESSLY ADADAR AM DO REPORT OF HIM AH BUT HE WAS SERVED PIONEERY TECHNOLOGY MISSHIONERY BEHIND ADARN'T HE ALL TAKE FOR GRANTED TO DAY AM COOKED PLEASE GIVE IT OUT SERVE HONESTLY WHEN PEOPLE WHEN I THINK OF SELFLESS SERVICE TRULY S LFLASOVIS A OYOLISTICAL TE VIC AND A SINCE THEN HE ALSO WAS AT THE IE FORBADAN AH WHICH WE ARE GONG TO TOUCH ON WITH PRATUSIUS OTHER COFOUNDER\",\n",
              " \"A PRATUSATA PIECTI VAMFA ITIACAZURIC AH HE WAS SIRTER IBIUMRI SEARGE WITH AT MICHOSOP RESEARCH PLAYING A KEYLOLD A AND A FACULTYA DIDEMADRAS A AND AT AIR FOR ABOUT IT SO THAT'S A LITTLE BLIEF INTRODUCTION ABOUT THEM THESE GUAYS ARE MODEST MODEST ENGINEERS A SO THEY DON'T DO THEY DON'T HAUNT A SO FORGIVE ME OTUTING DERHAN HA IN THIS CASE A BUT LET'S JUM PLAYTIN A ABOUT THE MONEY FUNDING WOT TO A MILLION BUCKS MAN THAT'S A LOT OF MONEY LI EVERY ONTEBUNE HERE TE SAME I HELL IT FAT THESE GUAS DO WHAT DID THEY\",\n",
              " \"NESTO S SE THO WRITE SUCH A BIG CHEQUE Y I THINK I THINK ITS SIR I THINK IT'S A TRIEND OFE NEW TRIEND OF WHAT'S GOING ON IN INTIA I THINK THAT FOR THE VERY FIRST TIME I THINK EINVESTORS HAVE LOOKED AT YONO LET'S TRY AND BUILL SOMETHING DECK OUT OF THE COUNTRY AND LET'S TRY TO FIG IT OUT HOW TO BUILT SOMETHING THERE'S A FOUNDATION OF DICNOLEGIA AN IND THAT'S REALLY WHAT'S WHAT'S REALLY EXCITING YOU KNOW AND I THINK THAT TER A ABOUT A YOU KNOW A ES AS ASER A WHILE I WAS M NTIONING FOR ABAST FIFTEEN YEARS I'VE\",\n",
              " \"BEEN KANDLE WORKY IN KAND O FINO A BOTH BERDIGED IN PUBLIC IN PLASTACCER AND AN AN ANKIND OF FUR A NON PROPRATE KIND OF THINGS AND BUT QUENTIS WOL THING OF GENRTIBEI CAME ABOUT I I YOU KNOW WA SAI LOOKI HOW CAN I ACTUALLY MAKE A DIFFERENCE IN THIS PASE AND I SAID MAYBE THIS IS THE OPPORTUNITY TO ACTUALLY COME OUT AND AND AN REALLY BEREIS SOMETHING ER YO AND AND THE ONLY WAY THAT REALIZE THAT YOU CAN DO THIS ACTUAL IN E ININ EA A PIPE SECTERAND I THINK THAT'S AND THEN E WHEN WE WENT OUT THERE AND WE SAID WE\",\n",
              " \"WANT TO BUILD SOMETHING WHICH IS A CONTINUATION RIGHT A MINUT FUNDAMENTALLY THE QUESTION IS ATHE REASON OF WHAT WE WANT TO TO IT SURVA MAY I IS WE WANT TO BASE CHEAKMATES AND TI AVAILABLE AN ACCESSIBLE TO THE PEOPLE IN THE COUNTRY AND THAT'S THAT'S THE INDEPENDENT AND WANT HE SAID THAT WE WANT TO DO THIS THERE WAS A RESIDENCE A IMPY INVESTMENT FABILITY AND I THINK IT'S IT'S A RESPONSIBILITY TO RARLY TO SHOW THAT E THAT'S SOMETHING LIKE THIS CAN BE PUT OUT OF INDIA SO WE SEE THAT AS AS AS AS CONFIDENCE AND A\",\n",
              " \"RESPONSIBILITY AND I ALSO HOPE IT'S A FRIEND THAT THAT FEEL THAT THERE ARE MANY MORE PEOPLE LIKE LIKE US WHO ARE BACKED BECAUSE IF YOU LOOK AT IT MAYBE IT'S A L CH NUMBER IN A AH YOU KNOW IN THE INDIAN CONTEXTS BUT IN THE GLOBAL CONTEXT I THINK THAT AT JUST THERE SHOULD BE MANY MANY MOREON FRUNNERS WHO ARE BACK TO DO THINGS IN INDIAS COME WE'LL COME BACK TO THE MIDIVOLANTIC NURSE AND OFF IS THE OGASKIA BARTA BATHE SHES A CUTREN SO WE WILNOT COME BACK TO THE QUESTION BUT AGAIN WHAT BE ONE MILLION DOLLARS ALL\",\n",
              " \"OF WHAT YOU SAID IN ALL TWO MILLION DOLLARS O COUNT THAT'S A GOOD ON OF MONEY FOR O SCATA WHICH IN ALL WHICH HAS NOT YET BUILT ANYTHING WHAT ARE YOUING TO DO WITH ALL THIS MONEY A A H AA A LIKE AN JALLAO OF THEM I IN THE HOW PERFECT SOLISION FOR THE POWHI I THINKE TE LAST WEEK I'VE GOT CUTS OF COTS BLORTS OF PEOPLE HA A L TELLIN ME HOW I CAN NOBOT BUT I KNOW YOU FOR SOKAS WE LANDE ESELTER I WOUL RATHER THE COE NO BBUBUT HONESTY I THINK A THE KEY THING IN THIS IS IS TO FOOTING TOGETHER AMAZINGY AND WE\",\n",
              " 'ACTUALLY HAVE AN AMAZING TY BUT BELIEVE THAT IT IS TALENT THAT WOLL PLY THIS KIND OF THING AND FOTIS IT IS TO GET A GET KEY TALENT AND OF COURSE THE OTHER THING IS COMPUTEPISIS A EXTREMELY A EXPENSIVE COMPUTE WISE TO ACTUALLY DO THESE KINDS OF THINGS AND I THINK THAT THOS UP A TO PRIMARY THINGS THAT THAT A YOU LO USELES FOR RE I AM AM COMPUTING IT MY OWN HEAD AS HANTREFORA ITALIAN TOQUET YOU HAVE LET PRETTY COTEVE EQUAL HOW MUCH VALUE PAINIS AXCO TOQUET WE YOU WONT TATCH SON E HER SHU AM WE LSTO WIT WHAT',\n",
              " 'YOU GETS ACTUALLY BUILT WHAT I WHAT IS OPEN HAKI OPOWDY EXPLAIN OPENHATI MANY PEOPLE HER THE WHITE HATOF CAR NO MADDED SO I THINK OPENHAFI IS SOFUTZOFESTIVALL RIGHT WE COME FROM A PERSONALLY COUT FROM THE OPEN SORCE I KOSTEMENT AN AN ALSO FROM THE DIPIAI I KOSTE SO WE BELIEVE THAT FOR THIS TO WHAT WE NEED THE ECUSSTEN AH TO BE SUCCESSFUL AND AS A RESULT OF THAT ONE OF THE FIRST THINGS WE DID WAS HE THERE ARE THESE OPEN SORTS LARGE LANGUAGE MODELS THAT EXIST STRIGHT IMEAN EVERYBODY KNOWS ABOUT THE LAMAR',\n",
              " 'AMILY FOM MADAM THEYOLD SUME IN THERTHER OTHERS LIKE MISS TRAL TRAPON BUNCH OF OPENSORTS A A INO LARGE LANGUAGE MODELS AND THEN WE SAY IS THERE ANYWAY THAT THEY CAN EXISTIN OPENSOS MODEL AND TEACH IT LIKE WHIT SKIP TRIGHT A MIN AND THAT IS REALLY THE AH YOU KNOW WHAT ME TIS SY WHAT YO SAID THAT CAN WE DO SOMETHING LIKE THAT AND IS THIS A YOU NO RENIT FUGAL WAY OFF OFF ACTALY AH YOU KNOW MAKING A BOTTLES AH YOU KNOW A WORK IN IN IN DIVERSE LANGUAGES BECAUSE THE TRUTH IS STILL TO DAY AMETI FILOCATTHE AMOUNT',\n",
              " 'OF A DATE I ACKNOWLEDGE IT STILL ENGLISH DOMINATES MYSTICS AND AND AND I THINK THAT HOW DO YOU ACTUALLY TAKE AND MAKE IT UNDERSTANDING IN LANGUAGE UND STANDING YEN CONFEXED AND ALL OF THOSE THINGS IT INACTUALLY E IN AN EFFICIENT WAY AND THEREFORE THIS WAS AN ATTEMPT TO THAT AN ANISE OPENHATI IS A INOIS ISCANTI BESMOTHE LAMA A SEVEN BILLION MODEL BUT WI WIT A DESEIT EN MORE MODELS AND DIFFERENT LANGUAGES CONCISES AND THINGS LIKE THAT AS PART OF THIS AS PART OF THIS SERIES AND AND OF COURSE YOU KNOW WE WILL',\n",
              " \"BEL BUILDING FURTHER BODLS ON THOSE AND DOING OTHER THINGS TO TO ACTUALLY AND WE'LL ALSO HAVE ANY POINTS THAT PEOPLE CAN US SO THAF IT IS NOT IT'S DEPRITY A YU KNOW SOMETHING THAT PUGENT CAN A GET USE TWO THINGS AND BE THAT'S THAT'S THE ESSENCE OF OF A WHAT AZOPENHAV GUES SO WHAT DOES IT MEAN TO PEOPLE AN AUDIENCE HERE TOR EITHER BGERONT STARTAT WAT BUSINESS OR A AR OUR DEVELOPERS HOW SHOULD THEY LOOK AT MIETE I ASEED HIMSELF NOT NO YE NOT O ITHINK I THINK THE WAY YOU LOOK AT IS AT ME WE ARE ONE OF THE\",\n",
              " \"IMPORTANT THINGS THAT WE ARE DOING IS WE NOT JUST A B DING MODELS AH WE ARE ALSO REBUILDING AA PLATFORM A PLATFORM FOR DEVELOPERS WHERE CAN ACTUALLY USE A A COMBINATION OF VARIOUS DIFFERENT KINDS OF MODELS SUM WHICH ARE FROMAS SUMK TO OPEN SOR SUME WHICH MAY NOT WOPEN SUC AN ACTU HE TO AT TO POOL TOGETHER AND FIGURE OUT HOW YO DEPLY AR IN ALL PA GENIT EIR APPLIGATIONS AT SKALE AND UNDERSTAND AND VALUATE THEIR PERFORMANCE IN AN EFFICIENT MANNER AND THAT'S SOMETHING THAT WE'RE PLANNING TO DO IT THIS ENENO\",\n",
              " \"TISPLA POMIS NOTE IN THE NEXT SOBLEMONTHS WILL BE COMING OUT THERE BE AVAILABLE TO DEVELOP US BUT OF COURSE GHOSE WHO WANT TO START WITH THE OPONSORCE HER THINGS AN ANHACKDWITHET A POS PLEASE GO AHEAD THAT AS WELL THAT'S THAT'S PHENOMENAL COM BUT HOW DOES IT COME PAR TO OPEN THE ER ITSELF O ORGOUGALY SEE AT LEAST THE THINGS THAT WE ARE DOING NOW WRIGHT ABET ONE OF THE THINGS THAT WHEN WE TAUGHT ABOUT THE TEBUILDING SARA EXCEPT WE WANT TO BUILD A A FULLS THACT GENTETE THE ACCOMPANYAN RY DIFFERENT PEOPLE OF\",\n",
              " \"AND IN OUR UNDERSTANDING OF TE STACK IS THAT WE NEED TO KNOW HOW TO TRAIN MODES FROM SCRATCH WE NEED TO KNOW HOW TO KIND OF FIGURE OUT HOW TO DEPLY MODELS SULPRIAL WELL USCASUS AND WE NEED O PLAY THE CO SYSTEM TO MAKE SURE THAT WE CAN ACTUALLY DEPLY A POPULATION SKILL A AAPPLIGATIONS RIHTS'LL BE WHAT WE THINK AFOUT ALL OF THESE PIGS BUT STILL THE MODELS FOET O POOL OUT ARE NO FAIRLY SMALL MODELS TERFER MALL MODOS RIGHT THERE SEVEN TO MILLIA TO SEVEN BILLIAN KIND OF RANGE BITOT WORK WHALL THESE MODALS LIKE\",\n",
              " 'OPENY I AND AT LAROS MUCH BIGGER MATOS RIGT BUT WE WANT TO QUI QUIT WE WANT TO UNDERSTAND ITES ANT BE ABLE TO BILL THAT M USSLE TO DO ALL OF THESE THINGS A TO TO PWICKET TO MAKE IT AVAILABLE PEOPLE NOW GHOS SMORTI SAR I AM IN AS AS A SAD EH YOU KNOW I THINK THAT THERE IS SPACE FOR ALL OF THOSE THINGS AND I THINK ESWHEN ASTRY THAT WORTH TALKING ABOUT ELL ER IN THE DAY ARE WE BELIEVE THAT THESE SMALLER MODELS CANBOO A BERRY AN MANY MANY KIND OF DOBIAN THE TYPIC PLASS EXTREMELY WELL PROPERO EVEN BETTER THAN',\n",
              " \"THE N THE LARGER MODELS AND THAT IS LATLY ONE OF THE KI ERIAZAN AND SO THAT FOR THE VALUE OF THESE KINDS OF THINGS RIGHT WE'RE NOT AIMING IN THESE MOSETA BOTLES TO TO BUILD ANY AG I RIGHT THAT'S NOTTIR BOIK OUR GOLL IS TO MAKE THINGS THAT WORK EXTREMELY WELL FOR I DOMEAN SPECIFIC USECASES OR AR IN CESE AACCESSIBILITY TO LANGUAGE AND AN OROPOSPIT OBVIOUSLY ALL OF THIS UNIQUE TO ITIA WHAT IS UNIQUE ABOUT IT HERE MOLIK WHAT IS IS ANYTHING SPECIAL IN OUR EQUAL SYSTEM THAT THAT MAKES A SMALL MODELIS COCUSED WITH\",\n",
              " \"INDIAN LANGUAGES BETTER WHAT MONSER DE FRA POES SO I THINK THAT AMIN DERAR QUI TE FWO THINGS THAT ARE UNIQUE OF OUR UDIERI A THE FIRST THING IS I THINK THAT PIERRA WWIS FIRST LATIONS THE FOR I THINK WIS HAS TO BE THE FOR TO DOING THINGS A THE OTHER THING OF COURSE INDIA IS A EXTREMEL EH IT'S ACOST CONCIOUS COUNTRY FORT FROM FROM PROMA FROM ACOSPE SPECTOR NOW THERE THE I WOLD SAY THAT THERE ARE LOTS OF INTERESTIN USECASES WHERE YOU CAN USE OR A I AND THE COSS STRUCTTURE WORKS THAT WINT WENT W DEPENDING ON\",\n",
              " \"YOUR APPLICATION BUT WHEN YOU WANT TO SKILL THINGS TO A MASSIVE LEVEL AND MAKE IT WORK THEN THEN YOU HAVE TO FIGURE OUT HOW SMALL MINS WORK SO THAT'S SOMETHING THAT IS A ALSO SPECIFIC TO YE THE THIRD TING WHICH IS SPECIF DIA IS REALLY THE SUCCESS THAT INDIA HAS HAD IN BUILDING ALL THIS DIGID REPUBLICAN FRORSTRUCTURE WHEN YOU ADD THE AILER ON TOP OF IT THEN YOU CAN ACTUALLY GET DRAMATIC A ER YOU KNOW A DRAMATIC I THINK MULTIPLICATIVE E MENDORIAL EFFECTS BASED ON DOING THINGS LIKE THAT'S A PHENOMENAL POINT\",\n",
              " \"LAK YOU KNOWITS LIKE DIPIEI TO THE POWER OF THE AI ALMOST SOMEWAYS 'SA PART OF OTHER BUILDING OTHER NO BETTER PERSON THAN YOU I'M SO IN SOMEMODY WHAT I'M HEARING IS SMALL MODELS A SPECIALIZED WITH TRAINED WITH DICK SPECIFIC LANGUAGE DATA SUITED FOR INDIAN PROBLEMS AT THA COMPELLING COSSPOINT A WILL BE SUITED FOR A TRANSOLVING SOME WORLD AUTOMOUTOCVAKERS OR SOME COMPLEX PROBLEM RESOLVING COME BASIC PROBLEMS SPE ETICULY FOLCUS WITH ONVOICE OF PRACTICAL LANGUAGES THAT IS WHAT YOU SEE AS THE FUTURE AM I\",\n",
              " \"BATAFICING THE SKELETO NOT YET SO I THINK THAT CERTAINLY I MEAN A VOICE AND ANYON LANGUIGE IS UTTER UTOR AN IMPORTANT PART OSTRATEGY BUT WE WILL BE BUILDING AT YOUR ACCUSTOMED ODELS TO FAULT VARIOUS OTHER KINDS OF POBLERS AS WELL PRAY THAT'S NOT JUST LIMITED TO A I THINK INDIFFERENT DOMAINS WERE HEATED OVR E DOMAINS MAKING BELIEF TATES BASED ON UNIQUE DATER THAT THER ENTERPRISES HAVE INSO THAT'S THAT SOMETHING THAT PILOSA LOOKAT FAR ENOUGH SO COMING BACK TO THE I THE ELEPHANT IN THE ROO NO NO CONETTENDED\",\n",
              " \"WITH OPEN HAT HEAT AH WHAT ABOUT BABISHETE VALENTA CRUTRIM WHAT DOES YOUR TAKE ON THAT I THINK IT'S CLEAT I THINK IT'S ABSENCE IT'S WONDERFUL RATE I MEAN THE FACT THAT A TI TI EGNOLIT E EYE IS SO IMPORTANT THAT WE LEED PULTIBLE PEOPLE WORKING ON IT THE FACT THAT THERE ARE OTHER PEOPLE THINKING IS ACTUALLY VALIDIS THAT THIS IS AN IMPORTANT PROBLEM TO BE SOUGHT AND AND I THINK BETTE BETTER AN WE NEED EVERYBODY TO COME TOGETHER AND DO THAT SO I REALLY WELCOME THAT I THINK ITS ITS GREAT AND I THINK THAT ER\",\n",
              " \"THEY'LL BE DIFFERENT PEOPLE PLE HAVE DIFFERENT PATES AS TO HOW TO SOLVE THIS KIND OF PROBLEM AND AND HOPEFULLY AS A RESULT OF THAT THE ENTIRY KOSISTONE BENEFITS IV WONE MORE QUESTION AND THEN I WANT TO TALK ABOUT SOME OF THE PREDICTIONS THAT YOU BORGE MAN SOBEVIC AH I USUALLY ASK PEOPLE ABOUT WHAT D YOU THINK THE FUTURE'LL BE AND EVERYBODY USUALLY HEDGES AH I ASK VIG WHAT DO YOU THIK IS GOING TO HAPPEN AH BITE DECEMBER TWENTY TWENTY FOURTH WH R DO YOU THINK SITTING IN THIS ROOM ONE YEAR LATER WE CAN EXPECT\",\n",
              " \"AND HE MADE THREE BOLD CRETICTIONS SO I WON'T TALK WITH THAT BEFORE THAT HA ONE LAST QUESTION AM WHAT ARE THE TAP THREE APPLIGATIONS THAT YOU THINK AR RELEVATE FOR INDIA AM YOU WOLD TREAT THE TALWARD MEDICAL WH WRITTEN OF ANY FIX HOMETY WHAT IS WATS YO WANTED TO GIVE THE TOP TO THE APSAD WORIN YAPO EI SO AMENITE I THINK BETTER AS SAID THINGS LIKE A EDUCATION AT MECALARCHIER E IDIAS WHERE WERE WER WHERE I THINK THAT THINGS CAT CAN BE LEMINI THE WHOLE IDEA OF ALL THIS KIND OF A THE DEEP YY ASPECT OF IT IS\",\n",
              " \"ANOTHER MAJOR APPLICATION WHERE THINGS CAN HAPPEN IN AND HERE I'M GOT BUT ANTYSMESIFIQUA AND I THINK THE WHOME I NEW ITS PUD ALSO TALKED ABOUT WAS THE THE A CONCEPT OF SOFT CLARE I AND I THINK THAT AND AND CLEARLY WE HAVE A VERY LARGE SHOCKWERD INDUSTRIAN AND HOW TO HE IMAGINE THOSE THINGS IF IS CONFEX DESOSE SOMETHING THAT'S COULD FER ENOUGH AH I'LL GUESS READY FOR INTER CLAD ONES OLD PREDICTIONS YES NO I'M NOT HEARING IT YER SIR THIS IS LIKE A BIG DEAL HE'S THAT ONE OF THE SMARTEST GUIDES THAT I KNOW YOU\",\n",
              " \"AUGT TO MAKE THREE PREDICTIONS BELON TO HEAR IT 'R ALL RIGHT HELLO I ASKED HIM MA'AM WHAT DO YOU THINK IN OL HERE LATER WHAT ATE O YOU THINK YOU CAN EXPECT A HONEY CIME UP WITH THREETINGS THAT USUALLY PEOPLE FEEL VERY BLAD SERS AN LAST QUESTION LIKE THIS CAUSE THEY DON'T WANT TO BE CAUT ROF NOT TE BAK MAKE HIS BOLD AM SO HE MAY SECELY SAT THREE TINGS AND I WANT TO LIST OUT THE TREETINGS AND AN A ASK HIM ABOUT IT SO NUMMA ONE HE SAYS SA I WILL PREFER TO TALK ABOUT AUTERMATED CUSTOMER SERVICE THAN A REAL\",\n",
              " \"PERSON IT'S BECAUSE THEY GIVE ME A BETTER ANSWER THAT IS THE VIGRAGWAN'S PREDICTION OF A ONE SO BUR TWO IS THAT WHEN EVERYBODY IS TALKING ABOUT A G P U SHOTTAGE AM THE VIGE PREDICTS O THE BIA DIT GIPO GLUTTIN IT YE ETHINGS THALL BE TOO MUCH IME DETAN SO GO ON A SHART AND MEDIA STOP SAID LETANS AM AT NUMBE THREE WHICH WAS EXTREMELY UNEXPECTED HE SAID SOME COMPANIES WILL SUDDENLY DIE LIVIC THESE ARE MADWHAT I EXPECT AH SO THE ONE OF A QUICK YY TAO POT A EAT OF THET WIFE TWITES JUST THEA HOUR HE SAT AT AND\",\n",
              " \"TROW THE HERS SOLT OF SORD INTO IT BESIDES I DON'T THINK I QUITE SAID IT THE RA BET THITER WHILE I'S OUT A HITING BUT PUT IT WAT IT'S INTERESTING BUT I THINK THE FIRST THING A A THAT WE SAID IS I THINK THAT AAND AND I DON'T THINK THAT THISIS I THINK THET THERE WILL COME A TIME WHEN A YOU KNOW A IN IN ERIAS OF CUSTOMER SERVICE ET CETERA WHEN YOU WANT TO DO SOMETHING VERY SPECIFIC TO DAY YOU KNOW WHEN YOU CALLER WHEN YOU CALL SOME KIND OF A PART YOU ARE CLEANED UP YOU MOSTLY TRY TO DISCONNECT THE BALL OR\",\n",
              " \"ORGUNO YOU'RE EXTREMELY A UPSET TTYOU OPIN TOAVON BUT I THINK THAT THERE WILL COME A TIME ANANANIPREDIKE IS SOONER THAN LATER THAT YOU'LL ACTUALLY GET BETTER RESPONSES AH FROM THE BOT THAN WHAT THE HUMAN A REPRESENTATIVE THAT KES BE AVARAGE OVEN REPRESENTATIVE THAT PEOPLE TALK TO COULD GIVE AND I THINK THAT THAT'S JUST THE TRY TO SAT THAT THAT THAT THERE WILL COME A TIME WHERE YOU KNOW IT'S NOT A HUMOR YOU'RE TALKING TO BUT IT'S PROBABLY MORE LIKELY TO SOLVE YOUR INDENT THAN THAT THAN THE HUNIPESSETOR\",\n",
              " \"THAT'S TAT A SOMETHING THAT THAT TH T TER ATHAT I THINK THAT TE GOOD HAPPEN EFNETLY CONTRABORCHELL YARD AH WE'L LET IT GO WHAT ABOUT THE JEP OU GLUTT NO GES I I DON'T THINK THAT SO I THINK THE FACT THAT THERE IS A TREMENDOUS A SHORTAGE LIGKT NOW I THINK THAT TROTTET WIT PES BECAUSE THAT IS HOW THE CYCHES OF THINGS SCORE RIGHT WHEN WHEN HE WENTED IN O ITHINK THE FACT THAT THERE WAS SUCH A SEVERE SHORTES LAST YER YOU KNOW PATENTLY POSD A NUMBER OF THE FIT PLAYER STO TORAPATID B ARIOUS KINDS OF FORMS AND I\",\n",
              " \"THINK THA THAT TAT THAT'LL ALWAYS GO IN A CYCLE BUT YOU MAY WELL FIND OUT THAT THERE ARE MANY MANY MORE INTERESTING PROBLEMS THAT PEOPLE HER BRUSOLVE I'M II I STILL A REMEMBER A GENOL A WE WERE AT AT AT ATE GENIA EVENT IN BACK LORAT WE WERE TALKING TO PEOPLE ET WE SAID YOU KNOW HOW MANY PEOPLE HAVE ACCESS TO YOU KNOW AFOR EIGHT HUNDRED CESPOD THE QUESTION THAT HAD ASKED AND NOBODY IN THE ROOM AND THESE ARE ALL EXTREMELY ENTHUSIASTIC GENE AND NOBODY HAD ACTS AND I THINK THAT THING IS GOING TO CHANGE YOU WILL\",\n",
              " \"BE ABLE TO GET KINDS OF THINGS AND PEOPLE WHO WANT TO PACK AND DO THINGS WILL HAVE ACCESS TO DO THINGS AT IN IN WITHOUT YOU KNOW AHAVIC THE WRITER YOU NO A MADE CHECK CH LIVIG IS ALSO A SEMI CATECK TO DIE BEFORE HE WENT ITO ADARO I WOULD TAKE HIS PREDICTIONS VER YOU SELIOUS TENK SO I KNOW WHAT I OP O ILL SELL MY IMMEDIATE STOCK ANR I WOULD NOT DO THAT BUT THAT'S NOT WHAT I SAIY O'LL BLAME YOU FIRST I EA I BUT THE THIRD ONE IS PRETTY STRANGE HAH IT OLL COMPANIES A BARN COMPANYES DIE BUT YOU SAID SOME\",\n",
              " \"COMPANIS WILL SUDDENLY DIE WHAT DOES THAT MEAN NOR I THINK SEE I THINK THE THE INTERESTING THING IS AND I THINK THAT IF IIT COMES BACK WITH THE FUNDAMENTAL NATURE OF THE AIR A I IS A POOLFRIGHT AND YOU'LL HAVE TO USE THAT AND YOU HAVE TO USE THAT WITH IT YOUR BUSINESS PROCESS RIGHT AND HOW A I USE AND SO AND WHAT'S GOING TO HAPPEN IS THAT MINUT I THINK THIS IS TRUE A WITE A WIT YOU KNOW IT BEEN SOMEWHAT SET UP INTOMS OF YOU PEOPLE THEY SAID THAT THE PEOPLE WHO NEVERIS E I WILL BE WILL WILC MORE EFFECTIVE\",\n",
              " \"THAN THOSE WHO DON'T LEVERESKA AND THAT WILL SPEAK FOR ORGANIZATIONS ALSO ORGANI SATIONS THAT LEVERAGE EI IN FUNDAMENTI IN THEIR POOR BUSINESS POSTIES WILL BE MORE EFFECTIVE THAN THOSE WHO DON'T RIGHT AND I THINK THAT'S THE THING AND YOU WON'T KNOW THE DIFFERENCE UNTIL ONE DAY IT BECOMES TOO OBVIOUS AND IT'LL BE TOO IT AND I THINK THAT'S THE REASON WHY EVERYBODY MEADS TO THINK ABOUT WHAT IT MEANS FOT YOUR BUSINESS BECAUSE YOU EVERYTHING WILL BE FINE EVERYTHING WILL BE FIND THAN ONE DAY SOMEBODY IN YOR EH\",\n",
              " \"EITHER EITHER'S TILLY OR COMPETIT YOUR SPACE OF SOMETHING GRAND NEW COMING INTO YOUR SPACE WILL BEIMAGINING YOUR BUSINESS PROCESS COMPLETELY AND AT THAT STAGE YOU'LL FIND THAT IT'S E NO IT SIR IT'S A VERY BIG A VERY TALL HERO A MOUNTAIN TO PLAN AND THAT'S WHY I THINK IT'S PORTANT FOR BOTH PEOPLE AND ENITIES TO THINK ABOUT HOW THEY WILL A OUKNO DAY THEY WILL UPBAID THEMSELVES OR THEY WILL BORDIFY THEM WHOS PUSS IS TUN IN ATOUR THAT'S A VERY NOISE ACADEN WHO EVERYBODY HARWAS ON OR BUSINESS SHOULD REALLY THINK\",\n",
              " \"A OTTED BECAUSE LIFE WILL BE SIM AND THEN SUDDENLY SUDDENLY SOMETHING WILL INO THEN BE A STEP CHANGE AM TE MAKE OUT FEW MORE QUESTIONS BUT I SURE THE AUDIENCE AS A LOT OF QUESTIONS FOR YOU SO A HURRY DINONTIM NOKING SO AM DA'S LOOKING A LOT OF QUESTIONS SO LOP TO AH IS IT A MITE THAT BEGAN PASSO THANK YOU MY NAME IS CARTIC I VOT FORA A A HIP SERVICE INUSTRY SO YOURE SEEING THAT YOU'RE WALKING ON AH AH ELLELEM ARSORI SAS FIND YOUN DE LE LEM ON TOP OF LAMA MY BASY QUESTION FUNDAMENTAL GOSHELIS WE DON'T HAVE A\",\n",
              " 'FIND AM FOUNDATIONAL MPORTER FOR INDIA MOST OF Y MODALS AR BUSICALLY ISING AR ENGLISH AR THE DOSCANOFTINS FOR EXAMPLE EN AN ANDREW WAS TALKING ABOUT THE AR DOCCONAIZER SOMETHING EXCITEMENT SO ARE YOU WORKING ON ANYTHING LIKE THAT ARE YOU WE WANT TO USE BOSLI THE EXISTING MORTLS AND ON ON TOP OCKET ARE YOU GOING TOLOSK TISOLD QUESTION YOUR A CHERRYQUESTION WORT HOW COLT YOU HAV THO ITINK GREOF THE INTERESTING THING IS THAT IF YOU LOOK AT AN HAVACLYABLOG ON THIS ON O REP SITE I THING ONE OF THE THINGS THAT YO',\n",
              " \"ACTUALLY BILT ECASTOMISE TOKONITER WHICH ACTUALLY FUNDAMENTALLY CHANGES THE COSTO SOME OF THESE GENERATIONS INDITE LANGUAGES AND AND I THINK THAT YERE WILL NOT JUST FIND YOU WHERE ACTUALLY WE ARE BEVERAGING THE EXNIS PETENNY WE AD BE WAT'S KNOWN AS CONTINUAL PRETRAINING WHICH ACTUALLY BUT HAVE YOU SAID THAT YOU KNOW AH I THINK THAT AT WHENCE YE HAVE TO FIGURE OUT WHERE IS THE DETAIL TO TRAIN AN EXTRIMIALIZED MORTOR FROM SPATCH AND SOME OF THOSE THINGS ARE THINGS WHICH WILL HAPPEN AH O WHAT TIE BUT I THINK\",\n",
              " \"BETTER AHI THINK THATER YES I THINK THAT WE WILL BE PUDDLING VARIOUS KINDS OF THINGS BUT THE INTERESTING THING IS THAT IF I WANT TO CHEATE THE ACCESSIBILITY BROWNED WITH AN EXISTING OPEN SOCH MODL HOW DO I DO THAT AND THAT'S THE PROBLEM THAT WE HAVE ARD THAT WE THINK WE HAVE SORVED END AND THIS WOULD BE THE HEART OF A SO SIXCIDELY WELL EXPLAINED TO THE BLOGEVER I COULD UNDERSTAND IT SO I A E SHANT I WROTE FOR A FIT TOC MY QUESTION IS LE LIKE CHINA WE NEVER HEARD A CONSUMOFIZING ABPICATION A COMING OUT FROM\",\n",
              " \"MEDIA AND IN BEPRONVEPU KEPTUENON WHY DO YOU THINK IT BE DIFFERENT TO SPAMIN LAKE A EE BECAUSE E BUILD E T B I AND OTHER THINGS WILL TIS AF THE SAME PURPOSE BUT TO GREAT FIR WOR DID IT JOINO OR ROOTING LIKE ENAGH BECAUSE AA IVEN STREAT SECTOR NO OUTSIDE COUNTRY CAN B ORGIN NASA PROJECTS MAYBE COLGOTEGOTAT FUGURTO TET WATEDE IS THE MOTHER FOR ANIMATE COMPANY SO I DOLT RITHINK I THINK I THINK THAT THAT THE QUESTION IS ER I DON'T KNOW HE ANSWERED HIS QUESTIONS RIGHT ON ME MY AN I THINK THAT ER IT'S A DIFFICULT\",\n",
              " \"PATE BUT I DO BELIEVE AND AS I LIDE REPEATING THAT THE COMBENTORIAL EFFECT OF THE BLOSING GENEIT A BODSKALE IN ADDITION INTO ALONG WITH THE DIVII WORTH TA PIPLANITYVIA WILL HAVE PEOPLE AND I AND I THINK THAT OU IEN ER IT IS E THE THE INDENT IS THAT PEOPLE MEED TO BE ABLE TO USE IT AND THEY WILL VOTE QUIT THINGS THAT ARE MUSIFUL FOR THEM AND IF THAT DOESN'T HA N YOU ARE RIGHT THAT THAT I THINK THA TE WE HAVE TO FIGURE OUT WHAT IS THE MECHANISM OF THE DEBRI OF ABSIDE A BIT AN IN BOHOO WELL DO ITDIANS CONSUME\",\n",
              " 'NOT ATDESIBATE AMP SO STUADY BUT WE ARE OUT OF TIME TE IT WILL E OUTSIDER SO AR HE WILL BE ABLE TO ASK THE PURSUIT OF HEMPER A KENE ENE DIST TIGUAN LAST YER THANK YOU THANK YOU I HAVE MANISH KUTARI I AM FROM IAS YER BISA SCHOOL GUD THAT INT GOT A CHANCE TO ASK YOU THIS QUESTION YUDING LANSTIME THE VIT O FEW OF OUR EDUCATION IS FOVEVER TALKING ABOUT AT WE VER THERE WAS ONE FROM SCHOOL AND BIERRE THRON THE BI INSTITUTIONS WE WERE THINKING OF THESE PRESENT GENERATIONS HOW DO WE GET THEM INTO WHAT YOU ARE DOING',\n",
              " 'THERE IS ONE THING THAT THEY HAVE MED REGULARLY THAT THE C ONCENTRATIONS THAT THEY ARE WORKING ON BUT ARTIFICIAL INTELLIGENCE AND GETTING INTO THIS GETTING THEM INTO THEIR ACADEMICS AND MICKING THEM APART OF IT IS VERY IMPORTANT INCLUDING THE TRAINERS WHO TRAIN THEM MAKING THEM FUTURE READY TO WHAT YOU ARE DOING IS AMAZING AND THE SPEED THAT WITICH IS GROWING IT IS CALLING FOR A LOT OF FUR DRAINING THAT MEENS TO BE DONE CAN YOU FROM YOUR ANGLE TOLS O LIGHT ON HOW WE COULD MAKE THE FUTURE READY HOW THESE',\n",
              " 'PEOPLE WHO RE WHO OUR MANAGEMENT GRADUATES AND FROM SCHOOLS WHO AR COMING DOUT HOW DO WE GET INTO THIS PART OF TECHNOLOGY THAT YOU SPOKE ABOUT COUS THIS IS MISSUS LYLIA CHALLENGE BECAUSE I THINK EVERY ONE WILL MEET TO UNDERSTAND AT SOME LEVEL A WHAT BISTACHKNOWLEDGMET DOES AND I THINK THAT THE WE HAVE TO RETHI HOW WE GET EVERY ONE A INTO THIS CONDETIS TAT THIS KIND OF EDUCATION HAS YET MANY DIFFERENT CLEVER SIGHTS THAT A A FROM A POOR SET OF HAVING PEOPLE WHO ARE EXTREMELY GOOD AAAD AT SOMET AND THERE YOU',\n",
              " \"DON'T GAS MANY BUT TEN THET AR PASITY VAST SNAPPERS OF PEOPLE LOOK CAND ACTUALLY LEVERATES THESE GOODS BY THE WAY THE MOST IMPORTANT THING ABOUT AND IRIBY AT'S PART OF WHAT WEEKS TENELA LEV INTERESTING IS THAT HOW YOU USE IT AH YOUR YORGORGOR YOU'RE MY LEDS VERHE PI AT AND TO UNDERSTAND HOW TO ACT DELIVERATE THIS IN AN INTERESTING WAY IS SOMETHING THAT WE HAVE TO WIDLY AH IT TEATS MANY MANY PEOPLE AN AN AN AND BECAUSE IT IN ASKING THE ERYOU KNOW THINGS THE RIGHT WA AND AND HAVING THE RIGHT AND OF\",\n",
              " 'APPLICATIONS WILL MAKE A O GIPETS TO HOW PEOPLE ARE AN AH THANKEE THANK YOU VERY MUCH WILL MAK ALT VERY GOOD LUCK TO SARVOM AT GOOD LUCK TO IDIATIC AS WOL BEA NOT RIGHT ON RESORDET THANK THANKS BOLLA THANK YE MISTER RAGIVAN']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Load the GPT-2 tokenizer and model\n",
        "lm_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "lm_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Function to enhance transcription using a language model\n",
        "def enhance_transcription(transcription, lm_tokenizer, lm_model):\n",
        "    # Encode the transcription with attention mask\n",
        "    inputs = lm_tokenizer.encode(transcription, return_tensors='pt', padding=False, truncation=True)\n",
        "    attention_mask = torch.ones(inputs.shape, dtype=torch.long)\n",
        "\n",
        "    # Generate output from the language model\n",
        "    with torch.no_grad():\n",
        "        outputs = lm_model.generate(\n",
        "            inputs,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=len(inputs[0]) + 50,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=lm_tokenizer.eos_token_id\n",
        "        )\n",
        "    # Decode the output\n",
        "    enhanced_transcription = lm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return enhanced_transcription\n",
        "\n",
        "# Enhance each transcription\n",
        "# chunks = chunk_transcription(full_transcription_WAV2VEC2, max_chunk_length=512)\n",
        "\n",
        "# enhanced_transcriptions = [enhance_transcription(t, lm_tokenizer, lm_model) for t in full_transcription_WAV2VEC2]\n",
        "enhanced_chunks = [enhance_transcription(chunk, lm_tokenizer, lm_model) for chunk in chunks]\n",
        "\n",
        "# Print the enhanced transcriptions\n",
        "for original, enhanced in zip(full_transcription_WAV2VEC2, enhanced_chunks):\n",
        "    print(f\"Original: {original}\")\n",
        "    print(f\"Enhanced: {enhanced}\")\n",
        "    print(\"---------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4AoLiGrU61h",
        "outputId": "94e539ef-8447-414e-fdba-6bbb16060f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: C\n",
            "Enhanced: CONGRATULATIONS TO YOU MISTER ROCKERBAN FOR THAT AKS OBOSTE TORNING UT OBERTE AY EVERYBODY HOW ARE YOU AY NOT HEARING THIS AT ALL LIKE A POST LIE SHA AN EMPTY DOWNET OR SOMETHING LET'S HEAR IT ARE REGUISE THE WIG ALL RIGHT BETTER BE BECAUSE SA BE YOU HAVE A SUPA STAR GUESTIE AH YOU HERTH OF FORTY ONE MILLION DOLLARS A I DID GE ONSE IN IGNA SHE SAID AFTER THAT A SO O RIGNU ASK QUORTER WHAT FORTY MILLION DOLLARS SOHI BY THE END OF THIS CONVERSATION FOUQUET AH BUT LET GET STARTED AH I WANT INTRODUCE THE VICELAND OF THE WIG AND THE WIG IS A WIG AND I WANT TO BE A WIG AND I WANT TO BE A WIG AND I WANT TO BE A WIG AND I WANT TO BE A WIG AND I WANT TO\n",
            "---------\n",
            "Original: O\n",
            "Enhanced: AND PRATHIUCHISCOPONDE AS NOT HERE AH WE WANTED TO STARD WITH A FLANG OF VIDIOL AH OFF WHAT AM OPEN HATI DUS I ENCOURAGE ALL OF YOU TO GO AH TO THE WHEBSIDE'S AROMBADIAI AND CHECK IT OUT AM BUT LET ME START BY INTRODUCING LE VIK AH WE MAKE AS A DEAR FRIEND AND A HE IS VERY VERY MODEST ON O OF THE MOST MODEST GUIDES THAT I KNOW BUT HIS PERSONAL TURN TO THE QUVILA YOU GOT A PIECTI FROM KANIMELEN YOU SATTRED AND SOLD A COMPANY TO MAGMA AND THE OBLECANDIPUT BAKKITIA FROM ROBOT IN THE VALLEY ON THE SAME DAY AH WE HAVE A BANK AND A BANK AND A BANK AND A BANK AND A BANK AND A BANK AND A BANK AND A BANK AND A BANK AND A BANK AND A BANK AND A BANK\n",
            "---------\n",
            "Original: N\n",
            "Enhanced: ACTUALLY AH AND EVVEN IN INDIA FOR THE LAST SIXTEEN YEARS AND A WHAT MOST PEOPLE DON NOIS AM YOUR JONAT ADA AM HE'S BEEN THIRTEEN YEAR SELFLESSLY ADADAR AM DO REPORT OF HIM AH BUT HE WAS SERVED PIONEERY TECHNOLOGY MISSHIONERY BEHIND ADARN'T HE ALL TAKE FOR GRANTED TO DAY AM COOK PLEASE GIVE IT OUT SERVE HONESTLY WHEN PEOPLE WHEN I THINK OF SELFLESS SERVICE TRULY S LFLASOVIS A OYOLISTICAL TE VIC AND A SINCE THEN HE ALSO WAS AT THE IE FORBADAD AH WHICH WE ARE GONG TO TOUCH ON WITH PRATUSIUS OTHER COFOUNDER A SELFLESS SERVICE TRULY SELFLESS SERVICE TRULY SELFLESS SERVICE TRULY SELFLESS SERVICE TRULY SELFLESS SERVICE TRULY SELFLESS SERVICE TRULY SEL\n",
            "---------\n",
            "Original: G\n",
            "Enhanced: PRATUSATA PIECTI VAMFA ITIACAZURIC AH HE WAS SIRTER IBIUMRI SEARGE WITH A MICHROSOP RESEARCH PLAYING A KEYLOLD A AND A FACULTYA DIDEMATAS A AND AN AIR FOR ABOUT IT SO THAT'S A LITTLE BLIEF INTRODUCTION ABOUT THEM THESE GUAYS ARE MODEST MODEST ENGINEERS A SO THEY DON'T DO THEY DON'T HAUNT A SO FORGIVE ME OTUTING DERHAN HA IN THIS CASE A BUT LET'S JUM PLAYTIN A ABOUT THE MONEY FUNDING WOT TO A MILLION BUCKS MAN THAT'S A LOT OF MONEY LI EVERY ONTEBUNE HERE TE SAME I HELL IT FAT THESE GUAS DO WHAT DID THEY DO IT A LOT OF MONEY FUNDING WOT TO A MILLION BUCKS MAN THAT'S A LOT OF MONEY LI EVERY ONTEBUNE HERE TE SAME\n",
            "\n",
            "RAW Paste Data\n",
            "\n",
            "A B C D E\n",
            "---------\n",
            "Original: R\n",
            "Enhanced: NESTO S SEE WHO WRITE SUCH A BIG CHEQUE Y I THINK I THINK IT SIR I THINK IT'S A TRIEND OFE NEW TRIEND OF WHAT'S GOING ON IN INTIA I THINK THAT FOR THE VERY FIRST TIME I THINK THE INVESTORS HAVE LOOKED AT YONO LET'S TRY AND BUILL SOMETHING B DECK OUT OF THE COUNTRY AND LET'S TRY TO FIG IT OUT POW TO BUILT SOMETHING THERE'S A FOUNDATION OF DICNOLEGIA AN IND THAT'S REALLY WHAT'S WHAT'S REALLY EXCITING YOU KNOW AND I THINK THAT TER A ABOUT A YOU KNOW A ES AS ASER A WHILE I WAS M ENTIONING FOR ABAST FIFTEEN YEARS AND I THINK THAT'S A THING THAT I THINK IS A THING THAT I THINK IS A THING THAT I THINK IS A THING THAT I THINK IS A THING THAT I THINK IS A\n",
            "---------\n",
            "Original: A\n",
            "Enhanced: YEARS I'VE BEEN KINDLE WORKY IN KAND O FINO A BOTH BERDIGED IN PUBLIC AN PLASTACCER AND AN AN ANKIND OF FUR A NON PROPRATE KIND OF THINGS AND BUT QUENTES SWOL THING OF GENERTIVEI CAME ABOUT I I YOU KNOW WY SAI LOOKI HOW CAN I ACTUALLY MAKE A DIFFERENCE IN THIS PASE AND I SAID MAYBE THIS IS THE OPPORTUNITY TO ACTUALLY COME OUT AND AND AN REALLY BEREIS SOMETHING EH YO AND AND THE ONLY WAY THAT REALIZE THAT YOU CAN DO THIS ACTUAL IN E IN IN THEA A PIPE SECTERAND I THINK THAT'S AND THEN E WHEN WE WENT OUT THERE AND I WENT OUT THERE AND I WENT OUT THERE AND I WENT OUT THERE AND I WENT OUT THERE AND I WENT OUT THERE AND I WENT OUT THERE AND I WENT OUT THERE AND I WENT OUT THERE AND I\n",
            "---------\n",
            "Original: T\n",
            "Enhanced: AND WE SAID WE WANT TO BUILD SOMETHING WHICH IS A CONTINUATION RIGHT A MINUT FUNDAMENTALLY THE QUESTION IS ATHE REASON OF WHAT WE WANT TO TO IT SURVA MAY I IS WE WANT TO BASE CHEEKMATES AND TAI AVAILABLE AN ACCESSIBLE TO THE PEOPLE IN THE COUNTRY AND THAT'S THAT'S THE INDEPENDENT AND WHANT HE SAID THAT WE WANT TO DO THIS THERE WAS A RESIDENCE A IMP INVESTMENT FABILITY AND I THINK IT'S IT'S A RESPONSIBILITY TO RARLY TO SHOW THAT E THAT'S SOMETHING LIKE THIS CAN BE PUT OUT OF INDIA SO WE SEE THAT AS AS AS AS A RESIDENCE WE CAN DO THIS AND WE CAN DO THAT AND WE CAN DO THAT AND WE CAN DO THAT AND WE CAN DO THAT AND WE CAN DO THAT AND WE CAN DO THAT AND WE CAN DO THAT AND WE CAN DO THAT AND WE\n",
            "---------\n",
            "Original: U\n",
            "Enhanced: CONFIDENCE AND A RESPONSIBILITY AND I ALSO HOPE IT'S A GRIEND THAT THAT FEEL THAT THERE ARE MANY MORE PEOPLE LIKE LIKE US WHO ARE BACKED BECAUSE IF YOU LOOK AT IT MAYBE IT'S A L CH NUMBER IN A A YOU KNOW IN THE INDIAN CONTEXTS BUT IN THE GLOBAL CONTEXT I THINK THAT AT JUST THERE SHOULD BE MANY MANY MOREON FRUNNERS WHO ARE BACK TO DO THINGS IN INDIAS COME WE'LL COME BACK TO THE MIDIVOLANTIC NURSE AND OFF IS THE OGASKIA BARTA BATHE SHES A CUTREN SO WE WILNOT COME BACK TO THE QUESTION BUT AGAIN WHAT BE ONE OF THE WORST THINGS THAT CAN BE A MOST IMPORTANT THING THAT CAN BE A MOST IMPORTANT THING THAT CAN BE A MOST IMPORTANT THING THAT CAN BE A MOST IMPORTANT THING\n",
            "---------\n",
            "Original: L\n",
            "Enhanced: MILLION DOLLARS ALL OF WHAT YOU SAID IN ALL TWO MILLION DOLLARS O COUNT THAT'S A GOOD ON OF MONEY FORO SCATA WHICH IN ALL WHICH HAS NOT YET BUILT ANYTHING WHAT ARE YOUING TO DO WITH ALL THIS MONEY AAA AILIKE AN JALLA OW THEM I AD TE HOW PERFECT SOLISION FOR THE POWHI I THINKE E LAST WEAK I'VE GOT COTS OF COTS BLORTS OF PEOPLE AL TELLIN ME HOW I CAN NOBOT BUT I KNOW YOU FOR A SOK IL BE LANDE I'VE GOT COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF COTS OF C\n",
            "---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Generate frame-wise label probability (DONE ABOVE)\n",
        "\n",
        "Generate alignment probability (trellis):\n",
        "From the emission matrix, next we generate the trellis which represents the probability of transcript labels occur at each time frame.\n",
        "'''\n",
        "# We enclose the transcript with space tokens, which represent SOS and EOS.\n",
        "# transcript = \"SAMPLE|TEXT|\"\n",
        "# dictionary = {c: i for i, c in enumerate(labels)}\n",
        "\n",
        "# tokens = [dictionary[c] for c in transcript]\n",
        "# print(list(zip(transcript, tokens)))\n",
        "\n",
        "\n",
        "# def get_trellis(emission, tokens, blank_id=0):\n",
        "#     num_frame = emission.size(0)\n",
        "#     num_tokens = len(tokens)\n",
        "\n",
        "#     trellis = torch.zeros((num_frame, num_tokens))\n",
        "#     trellis[1:, 0] = torch.cumsum(emission[1:, blank_id], 0)\n",
        "#     trellis[0, 1:] = -float(\"inf\")\n",
        "#     trellis[-num_tokens + 1 :, 0] = float(\"inf\")\n",
        "\n",
        "#     for t in range(num_frame - 1):\n",
        "#         trellis[t + 1, 1:] = torch.maximum(\n",
        "#             # Score for staying at the same token\n",
        "#             trellis[t, 1:] + emission[t, blank_id],\n",
        "#             # Score for changing to the next token\n",
        "#             trellis[t, :-1] + emission[t, tokens[1:]],\n",
        "#         )\n",
        "#     return trellis\n",
        "\n",
        "\n",
        "# trellis = get_trellis(emission, tokens)\n",
        "'''\n",
        "BACKTRACKING :\n",
        "Once the trellis is generated, we will traverse it following the elements with high probability.\n",
        "The trellis matrix is used for path-finding, but for the final probability of each segment, we take the frame-wise probability from emission matrix.\n",
        "'''\n",
        "# class Point:\n",
        "#     token_index: int\n",
        "#     time_index: int\n",
        "#     score: float\n",
        "\n",
        "\n",
        "# def backtrack(trellis, emission, tokens, blank_id=0):\n",
        "#     t, j = trellis.size(0) - 1, trellis.size(1) - 1\n",
        "\n",
        "#     path = [Point(j, t, emission[t, blank_id].exp().item())]\n",
        "#     while j > 0:\n",
        "#         # Should not happen but just in case\n",
        "#         assert t > 0\n",
        "\n",
        "#         # 1. Figure out if the current position was stay or change\n",
        "#         # Frame-wise score of stay vs change\n",
        "#         p_stay = emission[t - 1, blank_id]\n",
        "#         p_change = emission[t - 1, tokens[j]]\n",
        "\n",
        "#         # Context-aware score for stay vs change\n",
        "#         stayed = trellis[t - 1, j] + p_stay\n",
        "#         changed = trellis[t - 1, j - 1] + p_change\n",
        "\n",
        "#         # Update position\n",
        "#         t -= 1\n",
        "#         if changed > stayed:\n",
        "#             j -= 1\n",
        "\n",
        "#         # Store the path with frame-wise probability.\n",
        "#         prob = (p_change if changed > stayed else p_stay).exp().item()\n",
        "#         path.append(Point(j, t, prob))\n",
        "\n",
        "#     # Now j == 0, which means, it reached the SoS.\n",
        "#     # Fill up the rest for the sake of visualization\n",
        "#     while t > 0:\n",
        "#         prob = emission[t - 1, blank_id].exp().item()\n",
        "#         path.append(Point(j, t - 1, prob))\n",
        "#         t -= 1\n",
        "\n",
        "#     return path[::-1]\n",
        "\n",
        "\n",
        "# path = backtrack(trellis, emission, tokens)\n",
        "# for p in path:\n",
        "#     print(p)\n",
        "\n",
        "'''\n",
        "MERGING THE WORDS\n",
        "The Wav2Vec2 model uses '|' as the word boundary, so we merge the segments before each occurance of '|'.\n",
        "\n",
        "'''\n",
        "#  # Merge words\n",
        "# def merge_words(segments, separator=\"|\"):\n",
        "#     words = []\n",
        "#     i1, i2 = 0, 0\n",
        "#     while i1 < len(segments):\n",
        "#         if i2 >= len(segments) or segments[i2].label == separator:\n",
        "#             if i1 != i2:\n",
        "#                 segs = segments[i1:i2]\n",
        "#                 word = \"\".join([seg.label for seg in segs])\n",
        "#                 score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "#                 words.append(Segment(word, segments[i1].start, segments[i2 - 1].end, score))\n",
        "#             i1 = i2 + 1\n",
        "#             i2 = i1\n",
        "#         else:\n",
        "#             i2 += 1\n",
        "#     return words\n",
        "\n",
        "\n",
        "# word_segments = merge_words(segments)\n",
        "# for word in word_segments:\n",
        "#     print(word)"
      ],
      "metadata": {
        "id": "Sp0zxNF-Egmy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "184e2d44-1ce0-4e1c-e6e3-88b3f1f2c765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nMERGING THE WORDS\\nThe Wav2Vec2 model uses '|' as the word boundary, so we merge the segments before each occurance of '|'.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3SpiTKWEsML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Final Implementations\n"
      ],
      "metadata": {
        "id": "6olAReGBCf2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faster-whisper"
      ],
      "metadata": {
        "id": "FLE1P5LWAHBa",
        "outputId": "c359205f-054c-4c6d-d211-ea893c7bc69c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: av<13,>=11.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (12.0.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (4.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.23.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.19.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (1.18.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.25.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.11.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "\n",
        "model_size = \"large-v3\"\n",
        "\n",
        "# Run on GPU with FP16\n",
        "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "# Run on GPU with INT8\n",
        "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
        "# Run on CPU with INT8\n",
        "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
        "model = WhisperModel(model_size, device=\"auto\", compute_type=\"default\")\n",
        "\n",
        "segments, info = model.transcribe(\"normalised_audio.wav\", beam_size=5, vad_filter = True, vad_parameters=dict(min_silence_duration_ms=50))\n",
        "\n",
        "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
        "\n",
        "for segment in segments:\n",
        "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
      ],
      "metadata": {
        "id": "Rx8m9SVmAKfK",
        "outputId": "cc66c0eb-6904-49fb-9cd9-c3eb04f7b1f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language 'en' with probability 0.932617\n",
            "[0.00s -> 2.10s]  Congratulations to you, Mr. Raghavan, for that.\n",
            "[2.28s -> 3.46s]  Thanks so much for joining us.\n",
            "[3.76s -> 4.22s]  Over to you.\n",
            "[8.44s -> 9.28s]  Hi, everybody.\n",
            "[9.64s -> 10.06s]  How are you?\n",
            "[10.82s -> 13.56s]  I'm not hearing this at all.\n",
            "[13.90s -> 16.86s]  It's like a post-lunch energy downer or something.\n",
            "[17.98s -> 18.76s]  Let's hear it.\n",
            "[19.42s -> 20.52s]  Are you guys awake?\n",
            "[21.68s -> 22.34s]  All right.\n",
            "[23.02s -> 26.90s]  You better be because we have a superstar guest here.\n",
            "[27.54s -> 28.90s]  You heard the $41 million.\n",
            "[29.40s -> 31.56s]  I didn't hear, honestly, anything that she said after that.\n",
            "[32.66s -> 38.34s]  So, we're going to ask for about $40 million by the end of this conversation, okay?\n",
            "[39.48s -> 40.54s]  But let's get started.\n",
            "[41.46s -> 44.94s]  I want to introduce Vivek and Pratyush, his co-founder, who's not here.\n",
            "[45.68s -> 50.88s]  We wanted to start with playing a video of what Open Hathi does.\n",
            "[51.14s -> 55.36s]  I encourage all of you to go to the website, serum.ai, and check it out.\n",
            "[56.44s -> 58.20s]  But let me start by introducing Vivek.\n",
            "[58.68s -> 59.76s]  Vivek is a dear friend.\n",
            "[60.54s -> 62.38s]  And he's very, very modest.\n",
            "[62.38s -> 64.26s]  Vivek is one of the most modest guys that I know.\n",
            "[64.78s -> 69.08s]  But his personal journey, Vivek, you've got a PhD from Carnegie Mellon.\n",
            "[69.20s -> 71.76s]  You started and sold a company to Magma.\n",
            "[72.42s -> 73.96s]  And Vivek and I moved back to India.\n",
            "[74.18s -> 76.48s]  We were both in the valley on the same day, actually.\n",
            "[77.32s -> 79.44s]  And you've been in India for the last 16 years.\n",
            "[80.16s -> 84.46s]  And what most people don't know is your journey at Aadhaar.\n",
            "[84.98s -> 87.82s]  He spent 13 years selflessly at Aadhaar.\n",
            "[88.78s -> 90.10s]  Nobody would have heard of him.\n",
            "[91.10s -> 92.10s]  But he was...\n",
            "[92.38s -> 97.30s]  He was a pioneering technology visionary behind Aadhaar, which we all take for granted today.\n",
            "[98.42s -> 100.16s]  So, please give it out.\n",
            "[100.78s -> 106.96s]  So, honestly, when I think of selfless service, truly selfless service, I always think of Vivek.\n",
            "[107.88s -> 112.36s]  And since then, he also was at AI for Bharat, which we're going to touch on,\n",
            "[112.74s -> 114.62s]  where he met Pratyush's other co-founder.\n",
            "[115.36s -> 117.84s]  Pratyush had a PhD from ETH at Zurich.\n",
            "[118.22s -> 119.84s]  He was at IBM Research.\n",
            "[120.48s -> 122.44s]  He was at Microsoft Research, playing a key role.\n",
            "[122.76s -> 126.04s]  And a faculty at IIT Madras, and at AI for Bharat.\n",
            "[126.46s -> 128.62s]  So, that's a little brief introduction about them.\n",
            "[128.82s -> 130.78s]  These guys are modest, modest engineers.\n",
            "[131.64s -> 133.24s]  So, they don't toot their own horn.\n",
            "[133.76s -> 137.00s]  So, forgive me for tooting their horn in this case.\n",
            "[137.44s -> 139.00s]  But let's jump right in.\n",
            "[140.28s -> 141.04s]  How about the money?\n",
            "[141.62s -> 141.98s]  Funding.\n",
            "[142.62s -> 143.68s]  41 million bucks, man.\n",
            "[143.74s -> 144.98s]  That's a lot of money.\n",
            "[145.50s -> 145.68s]  Right?\n",
            "[145.76s -> 148.52s]  Every entrepreneur here is saying, what the hell did these guys do?\n",
            "[148.84s -> 151.52s]  What did the investors see to write such a big check?\n",
            "[151.52s -> 158.10s]  You know, I think it's a trend, a new trend of what's going on in India.\n",
            "[158.18s -> 163.08s]  I think that for the very first time, I think investors have looked at, you know,\n",
            "[163.42s -> 166.02s]  let's try and build something deep tech out of the country.\n",
            "[166.40s -> 170.48s]  And let's try to figure out how to build something as a foundational technology.\n",
            "[170.48s -> 173.54s]  And that's really what's really exciting, you know.\n",
            "[173.54s -> 181.52s]  And I think that about, you know, as Bala was mentioning for the past 15 years,\n",
            "[181.52s -> 190.54s]  I've been kind of working in kind of, you know, both digital public infrastructure and kind of non-profit kind of things.\n",
            "[190.78s -> 199.12s]  But when this whole thing of generative AI came about, I, you know, we said, okay, how can I actually make a difference in this space?\n",
            "[199.12s -> 206.26s]  And I said, maybe this is the opportunity to actually come out and really build something, you know.\n",
            "[206.26s -> 211.26s]  And the only way that we realize that we can do it is actually in the...\n",
            "[211.52s -> 212.72s]  private sector.\n",
            "[212.72s -> 213.80s]  And I think that's that.\n",
            "[213.80s -> 218.22s]  And then when we went out there and we said we want to build something which is a continuation, right?\n",
            "[218.22s -> 229.74s]  I mean, fundamentally, the question is, the reason of what we want to do at Servam AI is we want to basically make generative AI available and accessible to the people in the country.\n",
            "[229.88s -> 231.40s]  And that's the intent.\n",
            "[231.40s -> 236.30s]  And when we said that we want to do this, there was a resonance in the investment community.\n",
            "[236.52s -> 241.50s]  And I think it's a responsibility to really to show that that's something like this.\n",
            "[241.52s -> 242.96s]  This can be built out of India.\n",
            "[242.96s -> 246.80s]  So we see that as confidence and a responsibility.\n",
            "[246.80s -> 252.40s]  And I also hope it's a trend that, you know, that there are many more people like us who are backed.\n",
            "[252.40s -> 265.02s]  Because if you look at it, maybe it's a large number in a, you know, in the Indian context, but in the global context, I think there should be many, many more entrepreneurs who are back to do things in India.\n",
            "[266.02s -> 267.64s]  I'm going to come back to the many more entrepreneurs.\n",
            "[267.64s -> 271.00s]  And obviously, I'm going to ask you about Bhavesh's Cruthrin.\n",
            "[271.52s -> 273.42s]  So we're going to come back to that question.\n",
            "[273.98s -> 284.36s]  But again, $41 million, all of what you said, you know, $2 million, you know, that's a good amount of money for a startup, which, you know, which has not yet built anything.\n",
            "[284.94s -> 286.30s]  What are you going to do with all this money?\n",
            "[288.88s -> 289.92s]  I can solve the problem.\n",
            "[290.24s -> 291.98s]  I can have a perfect solution for the problem.\n",
            "[291.98s -> 297.10s]  I think in the last week, I've got lots of calls from lots of people telling me how I can.\n",
            "[297.64s -> 299.10s]  No, but I know you first.\n",
            "[299.22s -> 300.86s]  Okay, I'll be landed in the country the same day.\n",
            "[301.04s -> 301.66s]  I'm in front of the camera.\n",
            "[301.68s -> 309.44s]  No, but honestly, I think the key thing in this is to putting together an amazing team.\n",
            "[309.70s -> 315.14s]  And we actually have an amazing team, but believe that it is talent that will drive this kind of thing.\n",
            "[315.28s -> 317.94s]  And so it is to get key talent.\n",
            "[318.32s -> 319.64s]  And of course, the other thing is compute.\n",
            "[319.78s -> 325.20s]  This is extremely expensive compute-wise to actually do these kinds of things.\n",
            "[325.48s -> 330.24s]  And I think that those are the two primary things that, you know, we use this for.\n",
            "[330.52s -> 331.00s]  Okay.\n",
            "[332.52s -> 334.72s]  I'm computing in my own head as an entrepreneur.\n",
            "[334.98s -> 337.16s]  Talent, okay, you have like 20, 15 people.\n",
            "[337.66s -> 338.84s]  How much are you paying these guys?\n",
            "[338.98s -> 340.62s]  But okay, we won't touch on that.\n",
            "[341.28s -> 343.64s]  But let's talk about what you guys actually built.\n",
            "[343.82s -> 344.90s]  What is OpenHathi?\n",
            "[345.10s -> 348.72s]  How would you explain OpenHathi to many people here who might not know about it?\n",
            "[349.30s -> 359.86s]  So I think OpenHathi is, so first of all, right, we come from, I personally come from the open source ecosystem and also from the DPI ecosystem.\n",
            "[360.10s -> 361.64s]  So we believe that for.\n",
            "[361.88s -> 365.32s]  This to work, we need the ecosystem to be successful.\n",
            "[365.52s -> 372.72s]  And as a result of that, one of the first things we did was, hey, there are these open source large language models that exist, right?\n",
            "[372.92s -> 376.04s]  I mean, everybody knows about the Lama family from Meta.\n",
            "[376.24s -> 383.32s]  They also there are others like Mistral, there are a bunch of open source, you know, large language models.\n",
            "[383.52s -> 390.72s]  And then we said, is there any way that take an existing open source model and teach it language skills, right?\n",
            "[390.92s -> 391.32s]  I mean,\n",
            "[391.32s -> 397.16s]  And that is really the, you know, what we decide, what we said that can we do something like that?\n",
            "[397.36s -> 407.52s]  And is this a way of actually, you know, making models, you know, work in diverse languages?\n",
            "[407.72s -> 414.96s]  Because the truth is still today, I mean, if you look at the amount of data and knowledge, it's still English dominates these things.\n",
            "[415.16s -> 421.20s]  And I think that how do you actually take and make it understand Indian language, understand Indian context?\n",
            "[421.40s -> 425.04s]  And all of those things in actually in an efficient way.\n",
            "[425.24s -> 427.20s]  And therefore, this was an attempt to do that.\n",
            "[427.40s -> 433.68s]  And it's an open Hathi is, you know, is currently based on the Lama 7 billion model.\n",
            "[433.88s -> 442.08s]  But we will be releasing many more models in different languages, different sizes and things like that as part of this as part of this series.\n",
            "[442.28s -> 450.12s]  And of course, you know, we will be building further models on those and doing other things to actually and we also have endpoints that people can use.\n",
            "[450.32s -> 451.12s]  But it's not.\n",
            "[451.32s -> 455.36s]  It's definitely, you know, something that we can and can use to fix.\n",
            "[455.56s -> 459.96s]  And that's that's the essence of of what it's open.\n",
            "[460.16s -> 467.56s]  So what does it mean to people in the audience here who are either doing their own startups or a business or or developers?\n",
            "[467.76s -> 469.56s]  How should they look at?\n",
            "[469.76s -> 472.44s]  Oh, sorry, sorry.\n",
            "[472.64s -> 481.20s]  No, no, no. I think I think the way you look at it is that one of the important things that we are doing is we're not just building models.\n",
            "[481.36s -> 494.36s]  We are also building a platform, a platform for developers where you can actually use a combination of various different kinds of models, some which are from us, some open source, some which may not be open source.\n",
            "[494.56s -> 506.36s]  And actually to pull together and figure out how to deploy, you know, generated applications at scale and understand and evaluate their performance.\n",
            "[506.56s -> 509.36s]  And that's something that we are planning to do at this end.\n",
            "[509.56s -> 511.16s]  And this platform is, you know,\n",
            "[511.48s -> 515.48s]  in the next couple of months will be coming out there to be available to developers.\n",
            "[515.68s -> 522.56s]  But of course, those who want to start with the open source things and hack for that, of course, please go ahead and do that as well.\n",
            "[522.76s -> 524.56s]  That's phenomenal.\n",
            "[525.20s -> 530.09s]  But how does it compare to OpenAI itself or Google?\n",
            "[530.29s -> 533.25s]  See, at least the things that we are doing now, right?\n",
            "[533.45s -> 541.37s]  One of the things that when we thought about building server, we said we want to build a full stack generated API company.\n",
            "[541.37s -> 548.41s]  And different people and our understanding of the stack is that we need to know how to train models from scratch.\n",
            "[548.61s -> 554.33s]  We need to know how to kind of figure out how to deploy models to solve real world use cases.\n",
            "[554.53s -> 562.49s]  And we need to play in the ecosystem to make sure that we can actually deploy population scale applications.\n",
            "[562.69s -> 569.33s]  So we were thinking about all of these things, but still the models we were talking about are, you know, fairly small models.\n",
            "[569.53s -> 571.33s]  They're fairly small models, right?\n",
            "[571.53s -> 574.89s]  Seven to maybe up to seven billion kind of range we're talking about.\n",
            "[575.09s -> 580.25s]  While these models like OpenAI and Google are obviously much bigger, right?\n",
            "[580.45s -> 589.93s]  But we want to understand the techniques and be able to build that muscle to do all of these things to make it available to people.\n",
            "[590.13s -> 596.25s]  Now, those models are, I mean, as I said, you know, I think that there is space for all of those things.\n",
            "[596.45s -> 601.21s]  And I think as Sridhar was talking about earlier in the day,\n",
            "[601.53s -> 610.05s]  we believe that these smaller models can do very many, many kinds of domain specific tasks extremely well,\n",
            "[610.25s -> 612.45s]  probably even better than the larger models.\n",
            "[612.65s -> 614.69s]  And that is really one of the key areas.\n",
            "[614.89s -> 617.93s]  And so the value of these kinds of things, right?\n",
            "[618.13s -> 622.29s]  We are not aiming in these set of models to build any AGI, right?\n",
            "[622.49s -> 623.49s]  That's not our goal.\n",
            "[623.69s -> 630.97s]  Our goal is to make things that work extremely well for domain specific use cases or increase accessibility\n",
            "[631.37s -> 635.09s]  to which obviously all of this unique to India.\n",
            "[635.29s -> 637.29s]  What is unique about India?\n",
            "[637.49s -> 643.41s]  Like what is anything special in our ecosystem that that makes small models\n",
            "[643.61s -> 647.81s]  focused with Indian languages better for most of our problems?\n",
            "[648.01s -> 653.81s]  So I think that I mean, there are quite a few things that are unique about India, right?\n",
            "[654.01s -> 657.89s]  The first thing is, I think that we are a voice first nations.\n",
            "[658.09s -> 661.33s]  Therefore, I think voice has to be the core to doing things.\n",
            "[661.53s -> 667.57s]  The other thing, of course, India is extremely it's a cost conscious country\n",
            "[667.77s -> 669.65s]  from a cost perspective.\n",
            "[669.85s -> 674.29s]  Now, I would say that there are lots of interesting use cases where you can use\n",
            "[674.49s -> 678.73s]  open AI and the cost structure works that way depending on your application.\n",
            "[678.93s -> 682.65s]  But when you want to scale things to a massive level and make it work,\n",
            "[682.85s -> 685.13s]  then you have to figure out how small models work.\n",
            "[685.33s -> 688.33s]  So that's something that is also specific to India.\n",
            "[688.53s -> 691.09s]  The third thing which is specific to India is really\n",
            "[691.41s -> 695.85s]  the process that India has had in building all this digital public infrastructure.\n",
            "[696.05s -> 701.05s]  When you add the AI layer on top of it, then you can actually get dramatic,\n",
            "[701.25s -> 704.85s]  you know, dramatic, I think, multiplicative\n",
            "[705.05s -> 708.89s]  combinatorial effects based on doing things like that's a phenomenal point.\n",
            "[709.09s -> 712.33s]  Like, you know, it's like DPI to the power of AI almost in some ways.\n",
            "[712.53s -> 717.41s]  Part of other building other no better person than you.\n",
            "[717.61s -> 721.33s]  So in summary, what I'm hearing is all models specialized with\n",
            "[721.53s -> 726.93s]  trained with NIC specific language data suited for Indian problems at a compelling\n",
            "[727.13s -> 730.49s]  cost point will be suited for us, we're not solving some world\n",
            "[730.69s -> 734.57s]  autonomous vehicles or some complex problem, we're solving basic problems\n",
            "[734.77s -> 737.89s]  specifically focused on voice with multiple languages.\n",
            "[738.09s -> 739.45s]  That is what you see as the future.\n",
            "[739.65s -> 741.13s]  Am I paraphrasing this correctly?\n",
            "[741.33s -> 741.81s]  No. Yeah.\n",
            "[742.01s -> 746.77s]  So I think that certainly I mean, voice and Indian languages are an important part\n",
            "[746.97s -> 751.21s]  of our strategy, but we will be building custom models to solve various\n",
            "[751.41s -> 753.05s]  other kinds of problems as well.\n",
            "[753.25s -> 757.93s]  It's not just limited to, I think, in different domains or\n",
            "[758.13s -> 763.25s]  domains, making building things based on unique data that enterprises have.\n",
            "[763.45s -> 766.01s]  So that's something that we'll also get. Fair enough.\n",
            "[766.21s -> 771.53s]  So coming back to the elephant in the room, no pun intended with open Hathi.\n",
            "[771.73s -> 774.33s]  What about Babish Agarwal and Rutrim?\n",
            "[774.53s -> 776.37s]  What is your take on that? I think it's great.\n",
            "[776.57s -> 778.25s]  I think it's it's wonderful, right?\n",
            "[778.45s -> 780.33s]  I mean, the fact that\n",
            "[780.37s -> 785.97s]  the technology is so important that we need multiple people working on the fact\n",
            "[786.17s -> 789.81s]  that there are other people thinking is actually validates that this is\n",
            "[790.01s -> 795.33s]  an important problem to be solved. And I think that that we need\n",
            "[795.53s -> 799.01s]  everybody to come together and do that. So I really welcome that.\n",
            "[799.21s -> 800.09s]  I think it's great.\n",
            "[800.29s -> 803.21s]  And I think that there'll be different people will have\n",
            "[803.41s -> 806.25s]  different takes as to how to solve this kind of problem.\n",
            "[806.45s -> 810.01s]  And and hopefully as a result of that, the entire ecosystem.\n",
            "[810.01s -> 811.45s]  I think it's going to have a lot of benefits.\n",
            "[811.65s -> 813.21s]  I have one more question and then I want\n",
            "[813.41s -> 816.21s]  to talk about some of the predictions that you boldly made.\n",
            "[816.41s -> 819.25s]  So Vivek, I usually ask people about what do you think the future will be?\n",
            "[819.25s -> 820.93s]  And everybody usually hedges.\n",
            "[821.13s -> 824.81s]  I asked Vivek, what do you think is going to happen by December 2024?\n",
            "[824.85s -> 827.97s]  What do you think sitting in this room one year later we can expect?\n",
            "[828.17s -> 830.05s]  And he made three bold predictions.\n",
            "[830.25s -> 831.57s]  So I want to talk about that.\n",
            "[831.77s -> 833.53s]  Before that, I have one last question.\n",
            "[833.73s -> 838.09s]  What are the top three applications that you think are relevant for India?\n",
            "[838.29s -> 839.85s]  You would see the talk about medical.\n",
            "[840.01s -> 841.37s]  But let me pick somebody.\n",
            "[841.37s -> 844.85s]  What is what do you what do you think the top three apps are for India for AI?\n",
            "[845.05s -> 850.45s]  So, I mean, I think that, as you said, things like education and medical are\n",
            "[850.65s -> 855.13s]  clearly areas where where where where I think that can be leveraged.\n",
            "[855.33s -> 858.01s]  The whole idea of all these kind of\n",
            "[858.21s -> 862.33s]  the DPI aspect of it is another major application where things can happen.\n",
            "[862.53s -> 864.73s]  And here I'm talking about country specific work.\n",
            "[864.93s -> 869.77s]  And I think the whole idea we also talked about was the the concept of software.\n",
            "[869.77s -> 870.01s]  Right.\n",
            "[870.21s -> 874.81s]  And I think that and clearly we have a very large software industry and and how\n",
            "[875.01s -> 879.41s]  to imagine those things in this context is also something that's good.\n",
            "[879.61s -> 880.81s]  Fair enough.\n",
            "[881.01s -> 884.41s]  Are you guys ready for Vivek Raghavan's bold predictions?\n",
            "[884.61s -> 886.65s]  Yes. No, I'm not getting any yes.\n",
            "[886.85s -> 887.85s]  This is like a big deal.\n",
            "[888.05s -> 889.97s]  He's like one of the smartest guys that I know.\n",
            "[890.17s -> 891.33s]  He wants to make three predictions.\n",
            "[891.53s -> 892.97s]  You don't want to hear it.\n",
            "[893.53s -> 896.85s]  Right. So I asked him, what do you think?\n",
            "[897.05s -> 899.57s]  You know, a year later, what what do you think we can expect?\n",
            "[899.77s -> 901.09s]  And he came up with three things that\n",
            "[901.29s -> 904.65s]  usually people give very blah answers when you ask a question like this because\n",
            "[904.65s -> 908.33s]  they don't want to be caught wrong, not Vivek, Vivek is bold.\n",
            "[908.53s -> 910.33s]  So he basically said three things and I\n",
            "[910.53s -> 913.37s]  want to list out the three things and then ask him about it.\n",
            "[913.57s -> 917.05s]  So, number one, he says, I would prefer to talk to an automated\n",
            "[917.25s -> 921.65s]  customer service than a real person because they give me a better answer.\n",
            "[921.85s -> 924.45s]  That is Vivek Raghavan's prediction, number one.\n",
            "[924.65s -> 929.17s]  So number two is that when everybody is talking about a GPU shortage,\n",
            "[929.57s -> 932.65s]  Vivek predicts that there will be a GPU glut in India.\n",
            "[932.85s -> 934.69s]  He thinks there will be too much GPU.\n",
            "[934.89s -> 938.85s]  So you want a short media talk, it's a good time.\n",
            "[939.05s -> 941.81s]  And number three, which was extremely unexpected.\n",
            "[942.01s -> 944.97s]  He said some companies will suddenly die.\n",
            "[945.17s -> 949.45s]  OK, Vivek, these are not what I expected.\n",
            "[949.65s -> 952.89s]  So I want to quickly talk about each of them.\n",
            "[953.09s -> 956.69s]  Why you just came up with these and then we'll open the audience questions.\n",
            "[956.89s -> 959.49s]  So I don't think I quite said it the way that.\n",
            "[959.69s -> 963.77s]  But it's interesting.\n",
            "[963.97s -> 966.45s]  But I think the first thing\n",
            "[966.65s -> 970.89s]  that he said is I think that and I don't think that this is I think\n",
            "[971.09s -> 977.65s]  that there will come a time when, you know, in areas of customer service, etc.\n",
            "[977.85s -> 982.21s]  When you want to do something very specific today, you know, when you call\n",
            "[982.41s -> 986.49s]  when you call some kind of a bot, you actually end up mostly trying to disconnect\n",
            "[986.69s -> 989.45s]  the call or, you know, you're extremely upset.\n",
            "[989.61s -> 991.09s]  That you are talking to a bot.\n",
            "[991.29s -> 995.69s]  But I think that there will come a time and I predict it is sooner than later\n",
            "[995.89s -> 1000.77s]  that you will actually get better responses from the bot than what the human\n",
            "[1000.97s -> 1005.77s]  representative that is the average human representative that you could talk to could give.\n",
            "[1005.97s -> 1009.77s]  And I think that that's just that I just said that that that there will come\n",
            "[1009.97s -> 1014.25s]  a time where, you know, it's not a human you're talking to, but it's probably more\n",
            "[1014.45s -> 1017.89s]  likely to solve your intent than the human person.\n",
            "[1018.09s -> 1019.49s]  That's that's just something that.\n",
            "[1019.77s -> 1023.57s]  That that I think that could happen.\n",
            "[1023.77s -> 1026.29s]  Definitely controversial, but you let it go.\n",
            "[1026.49s -> 1028.09s]  What about the GPU glut?\n",
            "[1028.29s -> 1030.17s]  No idea. So I don't I don't think that.\n",
            "[1030.37s -> 1035.53s]  So I think that the fact that there is a tremendous shortage right now, I think\n",
            "[1035.73s -> 1039.81s]  that shortage is because that is how the cycles of things go right.\n",
            "[1040.01s -> 1042.49s]  When when when I think the fact that there\n",
            "[1042.69s -> 1048.53s]  was such a severe shortage last year, you know, basically caused a number of players\n",
            "[1048.73s -> 1049.49s]  to wrap up.\n",
            "[1049.77s -> 1054.37s]  And I think that that that that will always go in a cycle.\n",
            "[1054.57s -> 1057.05s]  But you may find out that there are many,\n",
            "[1057.25s -> 1059.97s]  many more interesting problems that people will be able to solve.\n",
            "[1060.17s -> 1064.73s]  I'm I still remember, you know,\n",
            "[1064.93s -> 1071.05s]  we were at the Gen EI event in Bangalore and we were talking to people and we said,\n",
            "[1071.25s -> 1075.21s]  you know, how many people have access to, you know, for a hundred.\n",
            "[1075.21s -> 1078.77s]  So the question that I asked and nobody in the room and these are all extremely\n",
            "[1078.97s -> 1081.53s]  enthusiastic and nobody had access.\n",
            "[1081.73s -> 1083.45s]  And I think that thing is going to change.\n",
            "[1083.65s -> 1087.21s]  You will be able to get these kinds of things and people who want to hack and do\n",
            "[1087.41s -> 1093.57s]  things will have access to these things without, you know, having to write a\n",
            "[1093.77s -> 1094.85s]  major check.\n",
            "[1095.05s -> 1097.89s]  Vivek is also a semi-connected guy before he went into Aadhaar.\n",
            "[1098.09s -> 1100.37s]  So I would take his predictions very seriously.\n",
            "[1100.57s -> 1103.57s]  So I know what I would sell my NVIDIA stock.\n",
            "[1103.77s -> 1106.77s]  I would not do that, but that's not what I said.\n",
            "[1106.97s -> 1107.97s]  I don't want to blame you.\n",
            "[1108.77s -> 1112.81s]  But the third one is pretty strange.\n",
            "[1113.01s -> 1115.05s]  You know, companies are born, companies die.\n",
            "[1115.25s -> 1117.81s]  But you said some companies will suddenly die.\n",
            "[1118.01s -> 1119.17s]  What does that mean?\n",
            "[1119.37s -> 1122.93s]  No, I think. See, I think the the interesting thing is\n",
            "[1123.13s -> 1126.93s]  and I think that it comes back to the fundamental nature of AI.\n",
            "[1127.13s -> 1129.09s]  AI is a tool, right?\n",
            "[1129.29s -> 1134.01s]  And you have to use that and you have to use that within your business process.\n",
            "[1134.21s -> 1136.21s]  Right. And how AI.\n",
            "[1136.41s -> 1138.65s]  And so what's going to happen is that\n",
            "[1138.97s -> 1144.25s]  I mean, I think this is true with, you know, when someone said in terms of people,\n",
            "[1144.45s -> 1149.97s]  they said that the people who leverage AI will be will will be more effective than\n",
            "[1150.17s -> 1153.73s]  those who don't leverage and that will speak for organizations.\n",
            "[1153.93s -> 1159.17s]  Also, organizations that leverage AI in fundamentally in their core business\n",
            "[1159.37s -> 1162.37s]  processes will be more effective than those who don't.\n",
            "[1162.57s -> 1163.97s]  Right. And I think that's the thing.\n",
            "[1164.17s -> 1168.61s]  And you won't know the difference until one day it becomes too obvious.\n",
            "[1168.93s -> 1170.17s]  And it will be too late.\n",
            "[1170.37s -> 1175.17s]  And I think that's the reason why everybody needs to think about what it\n",
            "[1175.37s -> 1179.21s]  means for your business, because you will everything will be fine.\n",
            "[1179.41s -> 1180.37s]  Everything will be fine.\n",
            "[1180.57s -> 1183.17s]  And one day somebody in your\n",
            "[1183.37s -> 1187.45s]  either competitor in your space or something brand new coming into your\n",
            "[1187.65s -> 1190.85s]  space will be imagining your business process completely.\n",
            "[1191.05s -> 1196.97s]  And at that stage, you'll find that it's you know, it's a it's a very big, very tall\n",
            "[1197.33s -> 1198.73s]  mountain to climb.\n",
            "[1198.93s -> 1204.29s]  And that's why I think it's important for both people and entities to think about\n",
            "[1204.49s -> 1208.73s]  how they will, you know, they will upgrade themselves or they will modify their\n",
            "[1208.93s -> 1210.89s]  processes to a new one.\n",
            "[1211.09s -> 1212.49s]  That's a very nuanced answer.\n",
            "[1212.69s -> 1216.17s]  Everybody here running a business should really think about it because life will\n",
            "[1216.37s -> 1221.65s]  be the same and then suddenly, suddenly something will be a step change.\n",
            "[1221.85s -> 1225.05s]  Vivek, I have a few more questions, but I'm sure the audience has a lot of questions.\n",
            "[1225.25s -> 1228.25s]  So how are we doing on time?\n",
            "[1228.25s -> 1230.17s]  OK, so\n",
            "[1230.37s -> 1231.81s]  that's OK. A lot of questions.\n",
            "[1232.01s -> 1236.70s]  So I'd love to set a mic that we can.\n",
            "[1240.58s -> 1242.14s]  Thank you. My name is Karthik.\n",
            "[1242.34s -> 1244.44s]  I work for\n",
            "[1244.64s -> 1246.60s]  IT service industry.\n",
            "[1246.80s -> 1250.04s]  So you're saying that you're working on\n",
            "[1250.99s -> 1254.83s]  LLM, sorry, fine tuned LLM on top of LAMA.\n",
            "[1255.03s -> 1258.63s]  My basic question, fundamental question is we don't have a fundamental\n",
            "[1258.63s -> 1259.59s]  model for India.\n",
            "[1259.79s -> 1264.91s]  Most of the models are basically using English or those kind of things.\n",
            "[1265.11s -> 1270.07s]  For example, Andrew was talking about the tokenizers and things like that.\n",
            "[1270.27s -> 1274.79s]  So are you working on anything like that or do you want to use mostly\n",
            "[1274.99s -> 1277.23s]  the existing models and run on top of them?\n",
            "[1277.43s -> 1281.11s]  Are you going to ask a good question, a cherry question?\n",
            "[1281.31s -> 1286.43s]  No, I think the interesting thing is that if you look at and have actually a blog\n",
            "[1286.63s -> 1288.51s]  on this on our website, I think one\n",
            "[1288.51s -> 1293.11s]  of the things that we actually built a customized tokenizer, which actually\n",
            "[1293.31s -> 1298.27s]  fundamentally changes the cost of some of these generations in Indian languages.\n",
            "[1298.47s -> 1301.19s]  And and I think that we're not just\n",
            "[1301.39s -> 1306.39s]  we're actually we are leveraging the existing, but we are doing what's known as\n",
            "[1306.59s -> 1310.31s]  continual pre-training, which actually but having said that, you know,\n",
            "[1310.51s -> 1315.43s]  I think that when we have to figure out where is the data to train an extremely\n",
            "[1315.43s -> 1318.35s]  large model from scratch and some of those things are things which\n",
            "[1318.55s -> 1320.39s]  will happen over time.\n",
            "[1320.59s -> 1326.71s]  But I think that I think that, yes, I think that we will be doing various kinds of things.\n",
            "[1326.91s -> 1331.59s]  But the interesting thing is that if I want to change the accessibility problem\n",
            "[1331.79s -> 1334.47s]  with an existing open source model, how do I do that?\n",
            "[1334.67s -> 1337.79s]  And that's the problem that we have that we think we have solved.\n",
            "[1337.99s -> 1339.67s]  And it's going to be the heart of this.\n",
            "[1339.87s -> 1342.11s]  So it's extremely well explained to the blog.\n",
            "[1342.31s -> 1344.31s]  Even I could understand it.\n",
            "[1345.31s -> 1348.11s]  Hi, I'm Prashant, I work for a fintech company.\n",
            "[1348.51s -> 1353.83s]  My question is, like, unlike China, we never had a consumer facing application\n",
            "[1354.03s -> 1359.27s]  coming out from India and in Web 1, Web 2, crypto and all.\n",
            "[1359.47s -> 1363.55s]  Why do you think it would be different this time in, like,\n",
            "[1363.75s -> 1371.10s]  AI? Because will the DPAI and other things will serve the same purpose\n",
            "[1371.30s -> 1378.62s]  what the Great Firewall did in China or do you think like in, because AI is a strategic sector,\n",
            "[1378.94s -> 1385.46s]  outside country can work in NASA projects, maybe all common content will go to them.\n",
            "[1385.66s -> 1390.46s]  What is the moat here for an Indian company?\n",
            "[1391.14s -> 1397.61s]  So I don't I think I think I think that the question is I don't know the answer\n",
            "[1397.81s -> 1402.37s]  to these questions, right, I mean, I think that it's difficult to predict.\n",
            "[1402.57s -> 1408.45s]  But I do believe, and as I'm repeating, that the combinatorial effect of being using\n",
            "[1408.77s -> 1413.69s]  AI at a large scale, in addition, along with the DPAI work that we've done in India,\n",
            "[1413.89s -> 1420.69s]  will have and I think that in the end, it is the intent is that people need to be\n",
            "[1420.89s -> 1423.77s]  able to use it and they will vote by things that are useful for them.\n",
            "[1423.97s -> 1429.93s]  And if that doesn't happen, you're right that I think that we have to figure out\n",
            "[1430.13s -> 1432.69s]  what is the mechanism for delivery of apps, right?\n",
            "[1432.89s -> 1436.77s]  I mean, how, where do Indians consume content?\n",
            "[1436.97s -> 1438.17s]  I'm so sorry.\n",
            "[1438.77s -> 1440.77s]  I'm out of time. Vivek will be outside.\n",
            "[1440.97s -> 1443.29s]  So he would be able to answer the question.\n",
            "[1443.49s -> 1446.25s]  Can I can I just take one last?\n",
            "[1446.45s -> 1448.01s]  Yeah, thank you. Thank you.\n",
            "[1448.21s -> 1450.73s]  I'm Manish Kothari. I'm from ISBR Business School.\n",
            "[1450.93s -> 1453.29s]  Good that I got a chance to ask you this question.\n",
            "[1453.49s -> 1455.21s]  During lunchtime, there were a few of our\n",
            "[1455.41s -> 1459.77s]  educationists whom we were talking about and there was one from school and we are\n",
            "[1459.97s -> 1464.01s]  from the MBA institutions, we were thinking of these present generations.\n",
            "[1464.21s -> 1467.45s]  How do we get them into what you are doing?\n",
            "[1467.65s -> 1468.73s]  There is one thing that they\n",
            "[1468.97s -> 1472.33s]  regularly that the concentrations that they are working on, but artificial\n",
            "[1472.53s -> 1475.89s]  intelligence and getting into this, getting them into their academics and\n",
            "[1476.09s -> 1480.13s]  making them a part of it is very important, including the trainers who train them.\n",
            "[1480.33s -> 1483.73s]  Making them future ready to what you are doing is amazing.\n",
            "[1483.93s -> 1485.85s]  And the speed that with which this is\n",
            "[1486.05s -> 1490.05s]  growing, it is calling for a lot of training that needs to be done.\n",
            "[1490.25s -> 1494.81s]  Can you, from your angle, throw some light on how we could make the future ready?\n",
            "[1495.01s -> 1498.57s]  How these people who are who are management graduates\n",
            "[1498.73s -> 1502.73s]  and from schools who are coming out, how do we get into this part of technology\n",
            "[1502.93s -> 1504.69s]  that you spoke about?\n",
            "[1504.89s -> 1509.89s]  So this is this is really a challenge because I think everyone will need to\n",
            "[1510.09s -> 1513.17s]  understand at some level what this technology does.\n",
            "[1513.37s -> 1518.21s]  And I think that we have to rethink how we get everyone into this.\n",
            "[1518.41s -> 1521.93s]  And that this is kind of education has yet many different levels.\n",
            "[1522.13s -> 1527.77s]  There are from a core set of having people who are extremely good at\n",
            "[1527.77s -> 1532.21s]  some and there you don't get as many, but then there are basically vast numbers\n",
            "[1532.21s -> 1534.09s]  of people who can actually leverage these tools.\n",
            "[1534.29s -> 1536.61s]  By the way, the most important thing about\n",
            "[1536.81s -> 1541.37s]  and maybe that's part of what makes an LLM interesting is that how you use it,\n",
            "[1541.57s -> 1547.21s]  your mileage varies by that and to understand how to actually leverage this\n",
            "[1547.41s -> 1552.37s]  in an interesting way is something that we have to widely teach many, many people.\n",
            "[1552.57s -> 1557.53s]  And because asking that, you know, things the right way.\n",
            "[1557.77s -> 1562.85s]  And having the right kind of applications will make a huge difference to how people\n",
            "[1563.05s -> 1564.05s]  also. Thank you.\n",
            "[1564.25s -> 1565.53s]  Thank you very much, Vivek.\n",
            "[1565.73s -> 1567.65s]  Very good luck to Sarvam and good luck to India.\n",
            "[1567.85s -> 1570.73s]  I think it's going to be a lot right on your shoulders.\n",
            "[1570.93s -> 1573.51s]  Thanks, Bala.\n",
            "[1573.71s -> 1574.83s]  Thank you, Mr. Raghavan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output_list = []\n",
        "\n",
        "# Process each segment and store the information in a dictionary\n",
        "for idx, segment in enumerate(segments):\n",
        "    chunk_dict = {\n",
        "        \"chunk_id\": idx + 1,\n",
        "        \"chunk_length\": segment.end - segment.start,\n",
        "        \"text\": segment.text,\n",
        "        \"start_time\": segment.start,\n",
        "        \"end_time\": segment.end,\n",
        "    }\n",
        "    sample_output_list.append(chunk_dict)\n",
        "\n",
        "# Print the result\n",
        "for chunk in sample_output_list:\n",
        "    print(chunk)"
      ],
      "metadata": {
        "id": "-Knw3CFSAlNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TODO : Speaker Diarization\n",
        "\n",
        "Detecting Speakers and labelling the data for each speaker."
      ],
      "metadata": {
        "id": "6ORqpGHJuvLs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8CuqSoPu2QU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}